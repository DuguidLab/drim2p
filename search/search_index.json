{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Installation","text":""},{"location":"#getting-started","title":"Getting started","text":"<p><code>drim2p</code> is an open-source package that facilitates the preprocessing of 2-photon calcium imaging recordings through a unified pipeline.</p>"},{"location":"#prerequisites","title":"Prerequisites","text":"<p><code>drim2p</code> is programmed in Python and you will need to have it installed on your machine. On all major platforms, it will be installed by default. But if you do not have it, follow the instructions available here.</p> <p><code>drim2p</code> takes as input <code>.raw</code> files outputted from a 2-photon imaging scope (e.g., Hyperscope). This is essentially all you will need to run the whole pipeline, except for a <code>settings.toml</code> file that is used for motion correction. You can find this extra file under <code>resources/motion_correction</code> in the repository.</p> <p>No specific preprocessing is necessary in order to use the software. However, since <code>.raw</code> files are in fact raw binary, some metadata is required for the software to be able to read the files. This metadata can take the form of an <code>.ini</code> file or an <code>.ome.xml</code> file. If an <code>.ini</code> file is present, it needs to have an <code>ome.xml.string</code> entry which contains a valid OME-XML string.</p> <p>For more details, see the tutorials overview and the tutorial on conversion.</p>"},{"location":"#installation-as-a-command","title":"Installation as a command","text":"<p><code>drim2p</code> is being developed with mostly Linux in mind. It is expected that most functionality should be available on macOS, but Windows support is not guaranteed. Instead, users should opt to use the Windows Subsystem for Linux available on Windows 10 and newer.</p> <p>If you run into troubles when trying to install <code>pipx</code>, refer to the latest documentation from their website to see if it fixes the problem. If you run into troubles when trying to install <code>drim2p</code> itself, have a read through the open and closed issues on the package's GitHub. If you do not find an answer after looking through those, feel free to open a new one, detailing your problem as best you can.</p>"},{"location":"#installing-pipx","title":"Installing <code>pipx</code>","text":""},{"location":"#on-linux","title":"On Linux","text":""},{"location":"#ubuntu-2304-or-above","title":"Ubuntu 23.04 or above","text":"<pre><code>sudo apt update\nsudo apt install pipx\npipx ensurepath\n</code></pre>"},{"location":"#fedora","title":"Fedora","text":"<pre><code>sudo dnf install pipx\npipx ensurepath\n</code></pre>"},{"location":"#other-distributions-using-pip","title":"Other distributions (using <code>pip</code>)","text":"<pre><code>python3 -m pip install --user pipx\npython3 -m pipx ensurepath\n</code></pre>"},{"location":"#on-macos","title":"On macOS","text":"<pre><code>brew install pipx\npipx ensurepath\n</code></pre>"},{"location":"#on-windows","title":"On Windows","text":"<p>On Windows, the recommended way to run <code>drim2p</code> is using the Windows Subsystem for Linux (WSL). If you do not have it enabled and do not wish to do so, you can follow the rest of these instructions. If you wish to continue with WSL, install <code>pipx</code> using the Linux instructions above. The recommended way to install <code>pipx</code> on Windows is using Scoop. Once Scoop is installed, run the following commands.</p> <pre><code>scoop install pipx\npipx ensurepath\n</code></pre> <p>However, you can also install it using <code>pip</code>:</p> <pre><code>python3 -m pip install --user pipx\n</code></pre>"},{"location":"#installing-drim2p","title":"Installing <code>drim2p</code>","text":"<p>Once <code>pipx</code> has been installed, run the following command:i</p> <pre><code>pip install drim2p\n</code></pre> <p>And that should be you sorted! From there, <code>drim2p</code> will be available as a command in your terminal.</p> <p>To ensure that everything installed property, you can run:</p> <pre><code>drim2p --help\n</code></pre> <p>If you see usage information printed out, all went well. If you see something telling you that <code>drim2p</code> is not a recognised command, ensure you have followed all the previous steps properly. If you are still having problem after that, consult the issues page on the package's GitHub.</p>"},{"location":"#installation-as-a-library","title":"Installation as a library","text":"<p>Most users will only need the command-line version of <code>drim2p</code>, but users willing to use its API in their own scripts can install it as a library.</p> <p>To do so, clone the repository locally:</p> <pre><code>git clone https://github.com/DuguidLab/drim2p\n</code></pre> <p>Navigate into the cloned directory:</p> <pre><code>cd drim2p\n</code></pre> <p>And install it in the Python environment you wish to use:</p> <pre><code>pip install .\n</code></pre>"},{"location":"#whats-next","title":"What's next?","text":"<p>For your first time working with the app, you should start by reading the typical workflow to get an overview of what you can do with the app.</p> <p>For more in-depth guides once you've got a good grip on the main capabilities of the application, see the tutorials which guide you through the commands and in-depth explanations of what each step entails.</p> <p>For documentation of the <code>drim2p</code> API to use in your own project, see the reference section.</p>"},{"location":"typical-workflow/","title":"Typical workflow","text":"<p>A typical workflow involves the following steps:</p> <ol> <li>Conversion from RAW to HDF5</li> <li>Motion correction</li> <li>ROI drawing</li> <li>Signal extraction and decontamination</li> <li>\u0394F/F\u2080 computation</li> </ol> <p>This provides a very broad overview of what the software provides. For a step-by-step guide going through each of these commands, you should read the tutorials.</p>"},{"location":"typical-workflow/#conversion-from-raw-to-hdf5","title":"Conversion from RAW to HDF5","text":"<p>This step converts the RAW binary files coming from a 2-photon scope into the HDF5 file format for easier storage.</p> <p>Command:</p> <pre><code>drim2p convert raw /path/to/your/recordings.raw\n</code></pre>"},{"location":"typical-workflow/#motion-correction","title":"Motion correction","text":"<p>This step corrects for motion artifacts in recordings.</p> <p>Command:</p> <pre><code>drim2p motion correct /path/to/your/recordings.h5 --settings-path /path/to/your/settings.toml\n</code></pre>"},{"location":"typical-workflow/#roi-drawing","title":"ROI drawing","text":"<p>This step allows drawing ROIs around cells for further preprocessing.</p> <p>Command:</p> <pre><code>drim2p draw roi /path/to/your/recordings.h5\n</code></pre>"},{"location":"typical-workflow/#signal-extraction-and-decontamination","title":"Signal extraction and decontamination","text":"<p>This step extracts \"true\" signals for the cells denoted by the drawn ROIs.</p> <p>Command:</p> <pre><code>drim2p extract signal /path/to/your/recordings.h5\n</code></pre>"},{"location":"typical-workflow/#ff0-computation","title":"\u0394F/F\u2080 computation","text":"<p>This step compute \u0394F/F\u2080 for extracted signals.</p> <p>Command:</p> <pre><code>drim2p delta /path/to/your/recordings.h\n</code></pre>"},{"location":"reference/","title":"drim2p","text":"<p>A dreamy 2-photon imaging processing pipeline.</p> <p>Args:     verbosity (int, optional):         Verbosity level. Level 0 is INFO (default). Level 1 is DEBUG.     quietness (int, optional):         Quietness level. Level 0 suppresses INFO messages. Level 1 suppresses         WARNING messages.     no_colour (bool, optional): Whether to disable logging colours.     version (bool, optional): Whether to print version version and exit.</p> <p>Usage:</p> <pre><code>drim2p [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  -v, --verbose  Set verbosity level. Level 0 is INFO (default). Level 1 is\n                 DEBUG.\n  -q, --quiet    Suppress log output. One '--quiet' suppresses INFO messages.\n                 Two '--quiet' and up suppresses WARNING messages.This\n                 overrides verbosity set using '--verbose'.\n  --no-colour    Disable logging colours.\n  -V, --version  Print version information.\n  --help         Show this message and exit.\n</code></pre> <p>Subcommands</p> <ul> <li>convert: Converts data to HDF5/NWB.</li> <li>deltaf: Computes \u0394F/F\u2080 for extracted signals.</li> <li>draw: Allows for drawing ROIs on HDF5 dataset.</li> <li>extract: Extracts signals.</li> <li>motion: Handles motion correction.</li> </ul>"},{"location":"reference/#drim2p-convert","title":"drim2p convert","text":"<p>Converts data to HDF5/NWB.</p> <p>Usage:</p> <pre><code>drim2p convert [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  --help  Show this message and exit.\n</code></pre> <p>Subcommands</p> <ul> <li>raw: Converts RAW data and metadata to HDF5.</li> </ul>"},{"location":"reference/#drim2p-convert-raw","title":"drim2p convert raw","text":"<p>Converts RAW data and metadata to HDF5.</p> <p>Note that SOURCE can be either a single file or a directory. If it is a directory, all the RAW files it contains will be converted.</p> <p>If '--ini-path' is not provided, it will default to the same path as the source file with the extension changed to '.ini'. If '--xml-path' is not provided, it will default to the same path as the source file with the extension changed to '.xml', and the 'XYT' ending changed to 'OME'. Note the OME-XML path is optional if the INI file contains the OME-XML as an entry.</p> <p>If <code>generate_timestamps</code> is set, a <code>.notes.txt</code> file with the same name as the RAW file should also be present.</p> <p>Usage:</p> <pre><code>drim2p convert raw [OPTIONS] [SOURCE]\n</code></pre> <p>Options:</p> <pre><code>  --ini-path FILE               Path to the INI file containing metadata about\n                                SOURCE. This is ignored if SOURCE is a\n                                directory.\n  --xml-path FILE               Path to the OME-XML file containing metadata\n                                about SOURCE. This is ignored if SOURCE is a\n                                directory.\n  -o, --out DIRECTORY           Output directory in which to put the converted\n                                files. Default is to output in the same\n                                directory as SOURCE.\n  -r, --recursive               Whether to search directories recursively when\n                                looking for RAW files.\n  -i, --include TEXT            Include filters to apply when searching for\n                                RAW files. This supports regular-expressions.\n                                Include filters are applied before any exclude\n                                filters.\n  -e, --exclude TEXT            Exclude filters to apply when searching for\n                                RAW files. This supports regular-expressions.\n                                Exclude filters are applied after all include\n                                filters.\n  -c, --compression [gzip|lzf]  Compression algorithm to use.\n  --aggression INTEGER RANGE    Aggression level to use for GZIP compression.\n                                Lower means faster/worse compression, higher\n                                means slower/better compression. Ignored if '\n                                --compression' is not GZIP.  [0&lt;=x&lt;=9]\n  --generate-timestamps         Whether to generate timestamps from the notes\n                                entries of the RAW files.\n  --force                       Whether to overwrite output files if they\n                                exist.\n  --help                        Show this message and exit.\n</code></pre>"},{"location":"reference/#drim2p-deltaf","title":"drim2p deltaf","text":"<p>Computes \u0394F/F\u2080 for extracted signals.</p> <p>Input arrays should be 1- or 2D arrays, where the first dimension is the one along which to compute f\u2080.</p> <p>If given a rolling window width, f\u2080 is computed for each entry along the first dimension of the input array. For values around the edges (within half of window width), the array is padded using the provided method (default is padding with 0s). Because of this, choosing a window that is too large can produce some unexpected values far into the array.</p> <p>Usage:</p> <pre><code>drim2p deltaf [OPTIONS] [SOURCE]\n</code></pre> <p>Options:</p> <pre><code>  -m, --method [percentile|mean|median]\n                                  Computation method for f\u2080.\n  -p, --percentile INTEGER        Percentile to use when computing f\u2080 using\n                                  the 'percentile' method. Ignored if\n                                  computing with a different method.\n  -w, --window-width INTEGER      Rolling window width in frames to use when\n                                  computing f\u2080. Pass 0 to disable it\n                                  (default). If greater than 0, the window is\n                                  used to compute a running value of f\u2080 for\n                                  each timepoint of the input, with padding\n                                  applied according to '--padding' around the\n                                  edges. If greater than 0, the rolling window\n                                  should be less than twice the size of the\n                                  first dimension of the input minus 1.\n  --padding [constant|reflect|wrap|edge]\n                                  Mode to use when padding the input. Ignored\n                                  if '--window-width' is 0.\n  --padding-value INTEGER         Constant value to use when padding using\n                                  'constant' mode. Ignored if '--padding' is\n                                  not 'constant'.\n  -r, --recursive                 Whether to search directories recursively\n                                  when looking for files.\n  -i, --include TEXT              Include filters to apply when searching for\n                                  files. This supports regular expressions.\n                                  Include filters are applied before any\n                                  exclude filters. They should be a semi-\n                                  colon-separated string of filters (e.g.,\n                                  'foo;bar' contains two filters, 'foo' and\n                                  'bar').\n  -e, --exclude TEXT              Exclude filters to apply when searching for\n                                  files. This supports regular expressions.\n                                  Exclude filters are applied after all\n                                  include filters. They should be a semi-\n                                  colon-separated string of filters (e.g.,\n                                  'foo;bar' contains two filters, 'foo' and\n                                  'bar').\n  --force                         Whether to overwrite output files if they\n                                  exist.\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"reference/#drim2p-draw","title":"drim2p draw","text":"<p>Allows for drawing ROIs on HDF5 dataset.</p> <p>Usage:</p> <pre><code>drim2p draw [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  --help  Show this message and exit.\n</code></pre> <p>Subcommands</p> <ul> <li>roi: Starts a napari GUI to draw ROIs on HDF5 datasets.</li> </ul>"},{"location":"reference/#drim2p-draw-roi","title":"drim2p draw roi","text":"<p>Starts a napari GUI to draw ROIs on HDF5 datasets.</p> <p>Note that SOURCE can be either a single file or a directory. If it is a directory, all the HDF5 files it contains will be queued for ROI drawing.</p> <p>Usage:</p> <pre><code>drim2p draw roi [OPTIONS] [SOURCE]\n</code></pre> <p>Options:</p> <pre><code>  -t, --template FILE             Path to the HDF5 file to read default ROIs\n                                  from. When provided, any ROIs already\n                                  present in the file will be used as the\n                                  default ROIs for all SOURCE file. Use in\n                                  conjunction with '--force' to overwrite any\n                                  existing ROIs with the template ones.\n  -d, --dataset TEXT              Full path from the root to the HDF5 dataset\n                                  to display.\n  -w, --projection-window INTEGER\n                                  Window size to use for grouped Z\n                                  projections.\n  -r, --recursive                 Whether to search directories recursively\n                                  when looking for HDF5 files.\n  -i, --include TEXT              Include filters to apply when searching for\n                                  HDF5 files. This supports regular-\n                                  expressions. Include filters are applied\n                                  before any exclude filters.\n  -e, --exclude TEXT              Exclude filters to apply when searching for\n                                  HDF5 files. This supports regular-\n                                  expressions. Exclude filters are applied\n                                  after all include filters.\n  --lazy                          Whether to lazily load the file. This will\n                                  speed up the GUI startup time but will slow\n                                  down any slicing when it is open. This will\n                                  also disable themean intensity projection.\n  --force                         Whether to ovewrite ROIs if some are found\n                                  in SOURCE. Otherwise, ROIs are appended. Be\n                                  careful when using this option as it will\n                                  lead to all ROIs being deleted when opening\n                                  a file.\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"reference/#drim2p-extract","title":"drim2p extract","text":"<p>Extracts signals.</p> <p>Usage:</p> <pre><code>drim2p extract [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  --help  Show this message and exit.\n</code></pre> <p>Subcommands</p> <ul> <li>signal: Extracts decontaminated signals from ROIs.</li> </ul>"},{"location":"reference/#drim2p-extract-signal","title":"drim2p extract signal","text":"<p>Extracts decontaminated signals from ROIs.</p> <p>Note that SOURCE can be either a single file or a directory. If it is a directory, all the HDF5 files it contains will be converted.</p> <p>By default, all provided files are treated as separate sessions. In order to process files together, use 'group-by-regex' to group paths together based on a regular expression. If you wish to group all files together, pass an empty string as the regular expression.</p> <p>Usage:</p> <pre><code>drim2p extract signal [OPTIONS] [SOURCE]\n</code></pre> <p>Options:</p> <pre><code>  --group-by-regex TEXT         Regular expression to use when grouping\n                                SOURCEs together. This results in the paths\n                                being preprocessed together based on the\n                                regex. This is ignored if SOURCE is a single\n                                file. Note that using this can lead to a very\n                                high memory usage depending on how many chunks\n                                needs to be loaded. Also note that for\n                                grouping to work, grouped files should have\n                                the same number of ROIs.\n  -d, --dataset TEXT            Full path from the root to the HDF5 dataset to\n                                process.\n  -r, --recursive               Whether to search directories recursively when\n                                looking for HDF5 files.\n  -i, --include TEXT            Include filters to apply when searching for\n                                HDF5 files. This supports regular-expressions.\n                                Include filters are applied before any exclude\n                                filters.\n  -e, --exclude TEXT            Exclude filters to apply when searching for\n                                HDF5 files. This supports regular-expressions.\n                                Exclude filters are applied after all include\n                                filters.\n  --dont-abort-on-skipped-file  Whether to keep working on a group if one or\n                                more of its files is skipped for any reason\n                                (e.g., file was already preprocessed by '--\n                                force' is not set).\n  --force                       Whether to overwrite output files if they\n                                exist.\n  --help                        Show this message and exit.\n</code></pre>"},{"location":"reference/#drim2p-motion","title":"drim2p motion","text":"<p>Handles motion correction.</p> <p>Usage:</p> <pre><code>drim2p motion [OPTIONS] COMMAND [ARGS]...\n</code></pre> <p>Options:</p> <pre><code>  --help  Show this message and exit.\n</code></pre> <p>Subcommands</p> <ul> <li>correct: Applies motion correction on HDF5 chunks.</li> </ul>"},{"location":"reference/#drim2p-motion-correct","title":"drim2p motion correct","text":"<p>Applies motion correction on HDF5 chunks.</p> <p>The motion correction is configured through a TOML settings file (available from the source code in the resources directory). The file allows customising behaviour such as the strategy to use or the maximum displacement allowed.</p> <p>Usage:</p> <pre><code>drim2p motion correct [OPTIONS] [SOURCE]\n</code></pre> <p>Options:</p> <pre><code>  -S, --strategy [markov|plane|fourier]\n                                  Strategy to use for motion correction. This\n                                  is ignored if a settings path is provided.\n  -d, --max-displacement TEXT     Maximum expected pixel displacement for\n                                  motion correction. This should be in the\n                                  form x,y. This is ignored if a settings path\n                                  is provided.\n  -s, --settings-path FILE        Path to the settings file to use. A strategy\n                                  and max displacements can be provided\n                                  together to remove the need for a settings\n                                  file.\n  -r, --recursive                 Whether to search directories recursively\n                                  when looking for RAW files.\n  -i, --include TEXT              Include filters to apply when searching for\n                                  RAW files. This supports regular-\n                                  expressions. Include filters are applied\n                                  before any exclude filters.\n  -e, --exclude TEXT              Exclude filters to apply when searching for\n                                  RAW files. This supports regular-\n                                  expressions. Exclude filters are applied\n                                  after all include filters.\n  -c, --compression [gzip|lzf]    Compression algorithm to use.\n  --aggression INTEGER RANGE      Aggression level to use for GZIP\n                                  compression. Lower means faster/worse\n                                  compression, higher means slower/better\n                                  compression. Ignored if '--compression' is\n                                  not GZIP.  [0&lt;=x&lt;=9]\n  --force                         Whether to overwrite output datasets if they\n                                  exist.\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"reference/API/SUMMARY/","title":"SUMMARY","text":"<ul> <li>drim2p<ul> <li>cli_utils</li> <li>convert<ul> <li>raw</li> </ul> </li> <li>deltaf<ul> <li>errors</li> </ul> </li> <li>draw<ul> <li>roi</li> </ul> </li> <li>extract<ul> <li>signal</li> </ul> </li> <li>io<ul> <li>errors</li> <li>raw</li> </ul> </li> <li>logs</li> <li>models</li> <li>motion<ul> <li>correct</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/API/drim2p/","title":"drim2p","text":""},{"location":"reference/API/drim2p/#drim2p.LoggingVerbosity","title":"<code>LoggingVerbosity</code>","text":"<p>Verbosity level of the package logging.</p> Source code in <code>src/drim2p/__init__.py</code> <pre><code>class LoggingVerbosity:\n    \"\"\"Verbosity level of the package logging.\"\"\"\n\n    ERROR = -2\n    WARNING = -1\n    INFO = 0\n    DEBUG = 1\n</code></pre>"},{"location":"reference/API/drim2p/#drim2p.drim2p","title":"<code>drim2p(verbosity=0, quietness=0, no_colour=False, version=False)</code>","text":"<p>A dreamy 2-photon imaging processing pipeline. \f</p> <p>Parameters:</p> Name Type Description Default <code>verbosity</code> <code>int</code> <p>Verbosity level. Level 0 is INFO (default). Level 1 is DEBUG.</p> <code>0</code> <code>quietness</code> <code>int</code> <p>Quietness level. Level 0 suppresses INFO messages. Level 1 suppresses WARNING messages.</p> <code>0</code> <code>no_colour</code> <code>bool</code> <p>Whether to disable logging colours.</p> <code>False</code> <code>version</code> <code>bool</code> <p>Whether to print version version and exit.</p> <code>False</code> Source code in <code>src/drim2p/__init__.py</code> <pre><code>@click.group(invoke_without_command=True)\n@click.option(\n    \"-v\",\n    \"--verbose\",\n    \"verbosity\",\n    required=False,\n    count=True,\n    help=\"Set verbosity level. Level 0 is INFO (default). Level 1 is DEBUG.\",\n)\n@click.option(\n    \"-q\",\n    \"--quiet\",\n    \"quietness\",\n    required=False,\n    count=True,\n    help=(\n        \"Suppress log output. One '--quiet' suppresses INFO messages. Two '--quiet' \"\n        \"and up suppresses WARNING messages.\"\n        \"This overrides verbosity set using '--verbose'.\"\n    ),\n)\n@click.option(\n    \"--no-colour\",\n    required=False,\n    is_flag=True,\n    help=\"Disable logging colours.\",\n)\n@click.option(\n    \"-V\", \"--version\", required=False, is_flag=True, help=\"Print version information.\"\n)\ndef drim2p(\n    verbosity: int = 0,\n    quietness: int = 0,\n    no_colour: bool = False,\n    version: bool = False,\n) -&gt; None:\n    \"\"\"A dreamy 2-photon imaging processing pipeline.\n    \\f\n\n    Args:\n        verbosity (int, optional):\n            Verbosity level. Level 0 is INFO (default). Level 1 is DEBUG.\n        quietness (int, optional):\n            Quietness level. Level 0 suppresses INFO messages. Level 1 suppresses\n            WARNING messages.\n        no_colour (bool, optional): Whether to disable logging colours.\n        version (bool, optional): Whether to print version version and exit.\n    \"\"\"  # noqa: D205, D301, D415\n    set_up_logging(verbosity, quietness, no_colour)\n\n    if version:\n        # Print version information and exit\n        software_version = __about__.__version__\n        python_version = platform.python_version()\n\n        version_info = f\"drim2p {software_version} (Python {python_version})\"\n        click.echo(version_info)\n\n        sys.exit()\n</code></pre>"},{"location":"reference/API/drim2p/#drim2p.set_up_logging","title":"<code>set_up_logging(verbosity, quietness, no_colour)</code>","text":"<p>Sets the logging level package.</p> <p>Parameters:</p> Name Type Description Default <code>verbosity</code> <code>int</code> <p>Verbosity level. Level 0 is INFO (default). Level 1 is DEBUG.</p> required <code>quietness</code> <code>int</code> <p>Quietness level. Level 0 suppresses INFO messages. Level 1 suppresses WARNING messages.</p> required <code>no_colour</code> <code>bool</code> <p>Whether to disable logging colours.</p> required Source code in <code>src/drim2p/__init__.py</code> <pre><code>def set_up_logging(verbosity: int, quietness: int, no_colour: bool) -&gt; None:\n    \"\"\"Sets the logging level package.\n\n    Args:\n        verbosity (int):\n            Verbosity level. Level 0 is INFO (default). Level 1 is DEBUG.\n        quietness (int):\n            Quietness level. Level 0 suppresses INFO messages. Level 1 suppresses\n            WARNING messages.\n        no_colour (bool): Whether to disable logging colours.\n    \"\"\"\n    if no_colour:\n        formatter = logging.Formatter(\n            \"[{asctime}] - [{levelname:&gt;9s} ] - {message}\",\n            style=\"{\",\n            datefmt=\"%Y-%m-%d %H:%M:%S\",\n        )\n    else:\n        formatter = logs.ColourFormatter()\n\n    console_handler = logging.StreamHandler()\n    console_handler.setFormatter(formatter)\n\n    _logger.addHandler(console_handler)\n\n    # Quietness overrides verbosity\n    level = -quietness if quietness &gt; 0 else verbosity\n    if level &lt;= LoggingVerbosity.ERROR:\n        _logger.setLevel(logging.ERROR)\n    elif level == LoggingVerbosity.WARNING:\n        _logger.setLevel(logging.WARNING)\n    elif level == LoggingVerbosity.INFO:\n        _logger.setLevel(logging.INFO)\n    elif level &gt;= LoggingVerbosity.DEBUG:\n        _logger.setLevel(logging.DEBUG)\n</code></pre>"},{"location":"reference/API/drim2p/cli_utils/","title":"cli_utils","text":""},{"location":"reference/API/drim2p/cli_utils/#drim2p.cli_utils.noop_if_missing","title":"<code>noop_if_missing(context, parameter, value)</code>","text":"<p>Exits the current context if the given value is <code>None</code>, else does nothing.</p> <p>This should be used as the callback of a <code>click.Parameter</code> when a <code>None</code> value for that parameter should cause the command to NO-OP.</p> <p>See <code>click</code>'s official documentation for rationale: https://github.com/pallets/click/blob/2d610e36a429bfebf0adb0ca90cdc0585f296369/docs/arguments.rst?plain=1#L43</p> <p>Parameters:</p> Name Type Description Default <code>context</code> <code>Context</code> <p>Current command context.</p> required <code>parameter</code> <code>Parameter</code> <p>Parameter for which this is a callback.</p> required <code>value</code> <code>Any</code> <p>Value to validate.</p> required <p>Returns:</p> Type Description <code>Any</code> <p>The value unchanged, guaranteed not to be <code>None</code>.</p> Source code in <code>src/drim2p/cli_utils.py</code> <pre><code>def noop_if_missing(\n    context: click.Context, parameter: click.Parameter, value: Any\n) -&gt; Any:\n    \"\"\"Exits the current context if the given value is `None`, else does nothing.\n\n    This should be used as the callback of a `click.Parameter` when a `None` value for\n    that parameter should cause the command to NO-OP.\n\n    See `click`'s official documentation for rationale:\n    https://github.com/pallets/click/blob/2d610e36a429bfebf0adb0ca90cdc0585f296369/docs/arguments.rst?plain=1#L43\n\n    Args:\n        context (click.Context): Current command context.\n        parameter (click.Parameter): Parameter for which this is a callback.\n        value (Any): Value to validate.\n\n    Returns:\n        The value unchanged, guaranteed not to be `None`.\n    \"\"\"\n    if value is None:\n        _logger.debug(\n            f\"Parameter '{parameter.human_readable_name}' \"\n            f\"of command '{context.command.name}' received a `None` value \"\n            f\"which was marked as a NO-OP.\"\n        )\n        context.exit(0)\n\n    return value\n</code></pre>"},{"location":"reference/API/drim2p/logs/","title":"logs","text":"<p>Custom logging functionality helpers.</p>"},{"location":"reference/API/drim2p/logs/#drim2p.logs.ColourFormatter","title":"<code>ColourFormatter</code>","text":"<p>               Bases: <code>Formatter</code></p> <p>A coloured log formatter meant for stdout.</p> References <p>Stack Overflow: https://stackoverflow.com/a/56944256</p> Source code in <code>src/drim2p/logs.py</code> <pre><code>class ColourFormatter(logging.Formatter):\n    \"\"\"A coloured log formatter meant for stdout.\n\n    References:\n        Stack Overflow: https://stackoverflow.com/a/56944256\n    \"\"\"\n\n    yellow = \"\\x1b[33;20m\"\n    red = \"\\x1b[31;20m\"\n    bold_red = \"\\x1b[31;1m\"\n    reset = \"\\x1b[0m\"\n\n    formatting = \"[{asctime}] - [{levelname:&gt;9s} ] - {message}\"\n\n    FORMATS: ClassVar[dict[int, str]] = {\n        logging.DEBUG: formatting,\n        logging.INFO: formatting,\n        logging.WARNING: yellow + formatting + reset,\n        logging.ERROR: red + formatting + reset,\n        logging.CRITICAL: bold_red + formatting + reset,\n    }\n\n    def format(self, record: logging.LogRecord) -&gt; str:\n        \"\"\"Formats the given record as a string.\n\n        Args:\n            record (logging.LogRecord): Record to format.\n\n        Returns:\n            The record formatter as a string.\n        \"\"\"\n        log_format = self.FORMATS.get(record.levelno)\n        formatter = logging.Formatter(\n            log_format, style=\"{\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n        )\n        return formatter.format(record)\n</code></pre>"},{"location":"reference/API/drim2p/logs/#drim2p.logs.ColourFormatter.format","title":"<code>format(record)</code>","text":"<p>Formats the given record as a string.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>LogRecord</code> <p>Record to format.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The record formatter as a string.</p> Source code in <code>src/drim2p/logs.py</code> <pre><code>def format(self, record: logging.LogRecord) -&gt; str:\n    \"\"\"Formats the given record as a string.\n\n    Args:\n        record (logging.LogRecord): Record to format.\n\n    Returns:\n        The record formatter as a string.\n    \"\"\"\n    log_format = self.FORMATS.get(record.levelno)\n    formatter = logging.Formatter(\n        log_format, style=\"{\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n    )\n    return formatter.format(record)\n</code></pre>"},{"location":"reference/API/drim2p/models/","title":"models","text":""},{"location":"reference/API/drim2p/models/#drim2p.models.ConfigKeyNotFoundError","title":"<code>ConfigKeyNotFoundError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Config key is missing.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Missing key.</p> required Source code in <code>src/drim2p/models.py</code> <pre><code>class ConfigKeyNotFoundError(Exception):\n    \"\"\"Config key is missing.\n\n    Args:\n        key (str): Missing key.\n    \"\"\"\n\n    def __init__(self, key: str) -&gt; None:\n        super().__init__(f\"Could not find a config entry for key '{key}'.\")\n</code></pre>"},{"location":"reference/API/drim2p/models/#drim2p.models.InvalidConfigValueError","title":"<code>InvalidConfigValueError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Value for the given key is not valid.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>Key of the given value.</p> required <code>value</code> <code>Any</code> <p>Invalid value.</p> required <code>valid</code> <code>Sequence[str]</code> <p>Sequence of valid values. This can be a sequence with a single value explaining what kind of value is expected.</p> required Source code in <code>src/drim2p/models.py</code> <pre><code>class InvalidConfigValueError(Exception):\n    \"\"\"Value for the given key is not valid.\n\n    Args:\n        key (str): Key of the given value.\n        value (Any): Invalid value.\n        valid (Sequence[str]):\n            Sequence of valid values. This can be a sequence with a single value\n            explaining what kind of value is expected.\n    \"\"\"\n\n    def __init__(self, key: str, value: Any, valid: Sequence[str]) -&gt; None:\n        super().__init__(\n            f\"Invalid value '{value}' for key '{key}'. \"\n            f\"Valid values are: {' '.join(valid)}\"\n        )\n</code></pre>"},{"location":"reference/API/drim2p/models/#drim2p.models.InvalidMotionConfigFileError","title":"<code>InvalidMotionConfigFileError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>TOML file is not valid as a motion config as it is missing the proper section.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the TOML file.</p> required Source code in <code>src/drim2p/models.py</code> <pre><code>class InvalidMotionConfigFileError(Exception):\n    \"\"\"TOML file is not valid as a motion config as it is missing the proper section.\n\n    Args:\n        path (pathlib.Path): Path to the TOML file.\n    \"\"\"\n\n    def __init__(self, path: pathlib.Path) -&gt; None:\n        super().__init__(\n            f\"Failed to parse TOML file: file does not have a \"\n            f\"'motion-correction' section. ({path})\"\n        )\n</code></pre>"},{"location":"reference/API/drim2p/models/#drim2p.models.MotionConfig","title":"<code>MotionConfig</code>  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Motion correction config.</p> <p>Fields:</p> <ul> <li> <code>strategy</code>                 (<code>Strategy</code>)             </li> <li> <code>displacement</code>                 (<code>tuple[int, int]</code>)             </li> </ul> Source code in <code>src/drim2p/models.py</code> <pre><code>class MotionConfig(pydantic.BaseModel):\n    \"\"\"Motion correction config.\"\"\"\n\n    strategy: Strategy = Strategy.Fourier\n    displacement: tuple[int, int] = (50, 50)\n\n    @classmethod\n    def from_file(cls, path: pathlib.Path) -&gt; MotionConfig:\n        \"\"\"Creates a motion correction config from a TOML file.\n\n        Args:\n            path (pathlib.Path): Path to the TOML file to parse.\n\n        Returns:\n            A motion correction object containing the information from the given TOML\n            file.\n\n        Raises:\n            InvalidMotionConfigFileError:\n                If the TOML file does not have 'motion-correction' section.\n        \"\"\"\n        with path.open(\"rb\") as handle:\n            contents = tomllib.load(handle)\n\n        dictionary = contents.get(\"motion-correction\")\n        if dictionary is None:\n            raise InvalidMotionConfigFileError(path)\n\n        return cls.from_dictionary(dictionary)\n\n    @classmethod\n    def from_dictionary(cls, dictionary: dict[str, Any]) -&gt; MotionConfig:\n        \"\"\"Parses a motion config from a dictionary.\n\n        Args:\n            dictionary (dict[str, Any]): Dictionary to parse as a motion config.\n\n        Returns:\n            A motion config containing the information from the given dictionary.\n\n        Raises:\n            ConfigKeyNotFoundError: If one of the required config keys is missing.\n            InvalidConfigValueError: If one of the required config values is invalid.\n        \"\"\"\n        strategy = dictionary.get(\"strategy\")\n        if strategy is None:\n            raise ConfigKeyNotFoundError(\"strategy\")  # noqa: EM101\n        try:\n            strategy = Strategy(strategy)\n        except ValueError:\n            raise InvalidConfigValueError(\n                \"strategy\",  # noqa: EM101\n                strategy,\n                [variant.name for variant in Strategy],\n            ) from None\n\n        displacement = dictionary.get(\"displacement\")\n        if displacement is None:\n            raise ConfigKeyNotFoundError(\"displacement\")  # noqa: EM101\n        # Displacement should be two values, [X, Y]\n        if not hasattr(displacement, \"__len__\") or len(displacement) != 2:  # noqa: PLR2004\n            raise InvalidConfigValueError(\n                \"displacement\",  # noqa: EM101\n                displacement,\n                [\"any two integer values\"],\n            )\n        try:\n            displacement = cast(\"tuple[int, int]\", tuple(map(int, displacement)))\n        except ValueError:\n            raise InvalidConfigValueError(\n                \"displacement\",  # noqa: EM101\n                displacement,\n                [\"any two integer values\"],\n            ) from None\n\n        return cls(strategy=strategy, displacement=displacement)\n</code></pre>"},{"location":"reference/API/drim2p/models/#drim2p.models.MotionConfig.from_dictionary","title":"<code>from_dictionary(dictionary)</code>  <code>classmethod</code>","text":"<p>Parses a motion config from a dictionary.</p> <p>Parameters:</p> Name Type Description Default <code>dictionary</code> <code>dict[str, Any]</code> <p>Dictionary to parse as a motion config.</p> required <p>Returns:</p> Type Description <code>MotionConfig</code> <p>A motion config containing the information from the given dictionary.</p> <p>Raises:</p> Type Description <code>ConfigKeyNotFoundError</code> <p>If one of the required config keys is missing.</p> <code>InvalidConfigValueError</code> <p>If one of the required config values is invalid.</p> Source code in <code>src/drim2p/models.py</code> <pre><code>@classmethod\ndef from_dictionary(cls, dictionary: dict[str, Any]) -&gt; MotionConfig:\n    \"\"\"Parses a motion config from a dictionary.\n\n    Args:\n        dictionary (dict[str, Any]): Dictionary to parse as a motion config.\n\n    Returns:\n        A motion config containing the information from the given dictionary.\n\n    Raises:\n        ConfigKeyNotFoundError: If one of the required config keys is missing.\n        InvalidConfigValueError: If one of the required config values is invalid.\n    \"\"\"\n    strategy = dictionary.get(\"strategy\")\n    if strategy is None:\n        raise ConfigKeyNotFoundError(\"strategy\")  # noqa: EM101\n    try:\n        strategy = Strategy(strategy)\n    except ValueError:\n        raise InvalidConfigValueError(\n            \"strategy\",  # noqa: EM101\n            strategy,\n            [variant.name for variant in Strategy],\n        ) from None\n\n    displacement = dictionary.get(\"displacement\")\n    if displacement is None:\n        raise ConfigKeyNotFoundError(\"displacement\")  # noqa: EM101\n    # Displacement should be two values, [X, Y]\n    if not hasattr(displacement, \"__len__\") or len(displacement) != 2:  # noqa: PLR2004\n        raise InvalidConfigValueError(\n            \"displacement\",  # noqa: EM101\n            displacement,\n            [\"any two integer values\"],\n        )\n    try:\n        displacement = cast(\"tuple[int, int]\", tuple(map(int, displacement)))\n    except ValueError:\n        raise InvalidConfigValueError(\n            \"displacement\",  # noqa: EM101\n            displacement,\n            [\"any two integer values\"],\n        ) from None\n\n    return cls(strategy=strategy, displacement=displacement)\n</code></pre>"},{"location":"reference/API/drim2p/models/#drim2p.models.MotionConfig.from_file","title":"<code>from_file(path)</code>  <code>classmethod</code>","text":"<p>Creates a motion correction config from a TOML file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the TOML file to parse.</p> required <p>Returns:</p> Type Description <code>MotionConfig</code> <p>A motion correction object containing the information from the given TOML</p> <code>MotionConfig</code> <p>file.</p> <p>Raises:</p> Type Description <code>InvalidMotionConfigFileError</code> <p>If the TOML file does not have 'motion-correction' section.</p> Source code in <code>src/drim2p/models.py</code> <pre><code>@classmethod\ndef from_file(cls, path: pathlib.Path) -&gt; MotionConfig:\n    \"\"\"Creates a motion correction config from a TOML file.\n\n    Args:\n        path (pathlib.Path): Path to the TOML file to parse.\n\n    Returns:\n        A motion correction object containing the information from the given TOML\n        file.\n\n    Raises:\n        InvalidMotionConfigFileError:\n            If the TOML file does not have 'motion-correction' section.\n    \"\"\"\n    with path.open(\"rb\") as handle:\n        contents = tomllib.load(handle)\n\n    dictionary = contents.get(\"motion-correction\")\n    if dictionary is None:\n        raise InvalidMotionConfigFileError(path)\n\n    return cls.from_dictionary(dictionary)\n</code></pre>"},{"location":"reference/API/drim2p/models/#drim2p.models.NotesEntry","title":"<code>NotesEntry</code>  <code>pydantic-model</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Notes entry from a <code>.notes.txt</code> files for a recording session.</p> <p>Fields:</p> <ul> <li> <code>start_time</code>                 (<code>datetime</code>)             </li> <li> <code>end_time</code>                 (<code>datetime</code>)             </li> <li> <code>file_path</code>                 (<code>Path</code>)             </li> </ul> Source code in <code>src/drim2p/models.py</code> <pre><code>class NotesEntry(pydantic.BaseModel):\n    \"\"\"Notes entry from a `.notes.txt` files for a recording session.\"\"\"\n\n    start_time: datetime.datetime\n    \"\"\"Start time of the notes entry recording.\"\"\"\n    end_time: datetime.datetime\n    \"\"\"End time of the notes entry recording.\"\"\"\n    file_path: pathlib.Path\n    \"\"\"File path the notes entry relates to.\"\"\"\n\n    @property\n    def timedelta(self) -&gt; datetime.timedelta:\n        \"\"\"Time delta between the entry's end and start times.\"\"\"\n        return self.end_time - self.start_time\n\n    @property\n    def timedelta_ms(self) -&gt; float:\n        \"\"\"Time delta in milliseconds between the entry's end and start times.\"\"\"\n        return self.timedelta / datetime.timedelta(milliseconds=1)\n\n    @property\n    def pure_file_path(self) -&gt; pathlib.PureWindowsPath:\n        \"\"\"A Windows file path representation of file path.\"\"\"\n        return pathlib.PureWindowsPath(self.file_path)\n</code></pre>"},{"location":"reference/API/drim2p/models/#drim2p.models.NotesEntry.end_time","title":"<code>end_time</code>  <code>pydantic-field</code>","text":"<p>End time of the notes entry recording.</p>"},{"location":"reference/API/drim2p/models/#drim2p.models.NotesEntry.file_path","title":"<code>file_path</code>  <code>pydantic-field</code>","text":"<p>File path the notes entry relates to.</p>"},{"location":"reference/API/drim2p/models/#drim2p.models.NotesEntry.pure_file_path","title":"<code>pure_file_path</code>  <code>property</code>","text":"<p>A Windows file path representation of file path.</p>"},{"location":"reference/API/drim2p/models/#drim2p.models.NotesEntry.start_time","title":"<code>start_time</code>  <code>pydantic-field</code>","text":"<p>Start time of the notes entry recording.</p>"},{"location":"reference/API/drim2p/models/#drim2p.models.NotesEntry.timedelta","title":"<code>timedelta</code>  <code>property</code>","text":"<p>Time delta between the entry's end and start times.</p>"},{"location":"reference/API/drim2p/models/#drim2p.models.NotesEntry.timedelta_ms","title":"<code>timedelta_ms</code>  <code>property</code>","text":"<p>Time delta in milliseconds between the entry's end and start times.</p>"},{"location":"reference/API/drim2p/models/#drim2p.models.Strategy","title":"<code>Strategy</code>","text":"<p>               Bases: <code>Enum</code></p> <p>Motion correction strategy.</p> Source code in <code>src/drim2p/models.py</code> <pre><code>class Strategy(enum.Enum):\n    \"\"\"Motion correction strategy.\"\"\"\n\n    Markov = \"HiddenMarkov2D\"\n    Plane = \"PlaneTranslation2D\"\n    Fourier = \"DiscreteFourier2D\"\n\n    @classmethod\n    def _missing_(cls, value: Any) -&gt; Any:\n        try:\n            value = value.lower()\n        except AttributeError:\n            return super()._missing_(value)\n\n        for variant in cls:\n            if variant.name.lower() == value:\n                return variant\n\n        return super()._missing_(value)\n</code></pre>"},{"location":"reference/API/drim2p/convert/","title":"convert","text":""},{"location":"reference/API/drim2p/convert/#drim2p.convert.convert","title":"<code>convert()</code>","text":"<p>Converts data to HDF5/NWB.</p> Source code in <code>src/drim2p/convert/__init__.py</code> <pre><code>@click.group()\ndef convert() -&gt; None:\n    \"\"\"Converts data to HDF5/NWB.\"\"\"\n</code></pre>"},{"location":"reference/API/drim2p/convert/raw/","title":"raw","text":""},{"location":"reference/API/drim2p/convert/raw/#drim2p.convert.raw.convert_raw","title":"<code>convert_raw(source, ini_path=None, xml_path=None, out=None, recursive=False, include=None, exclude=None, compression=None, compression_opts=None, generate_timestamps=False, force=False)</code>","text":"<p>Converts RAW data and metadata to HDF5.</p> <p>Note that SOURCE can be either a single file or a directory. If it is a directory, all the RAW files it contains will be converted.</p> <p>If '--ini-path' is not provided, it will default to the same path as the source file with the extension changed to '.ini'. If '--xml-path' is not provided, it will default to the same path as the source file with the extension changed to '.xml', and the 'XYT' ending changed to 'OME'. Note the OME-XML path is optional if the INI file contains the OME-XML as an entry.</p> <p>If <code>generate_timestamps</code> is set, a <code>.notes.txt</code> file with the same name as the RAW file should also be present.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Path</code> <p>Source file or directory to convert. If a directory, the default is to look for RAW files inside of it without recursion.</p> required <code>ini_path</code> <code>Path | None</code> <p>Path to the INI file containing metadata about SOURCE. This is ignored if SOURCE is a directory.</p> <code>None</code> <code>xml_path</code> <code>Path | None</code> <p>Path to the XML file containing metadata about SOURCE. This is ignored if SOURCE is a directory.</p> <code>None</code> <code>out</code> <code>Path | None</code> <p>Optional output directory for converted files.</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Whether to search directories recursively when looking for RAW files.</p> <code>False</code> <code>include</code> <code>str | None</code> <p>Include filters to apply when searching for RAW files. This supports regular-expressions. Include filters are applied before any exclude filters.</p> <code>None</code> <code>exclude</code> <code>str | None</code> <p>Exclude filters to apply when searching for RAW files. This supports regular-expressions. Exclude filters are applied after all include filters.</p> <code>None</code> <code>compression</code> <code>COMPRESSION | None</code> <p>Compression algorithm to use.</p> <code>None</code> <code>compression_opts</code> <code>int | None</code> <p>Compression options to use with the given algorithm.</p> <code>None</code> <code>generate_timestamps</code> <code>bool</code> <p>Whether to generate timestamps from the notes entries of the RAW files. A \".notes.txt\" file should be present along the RAW file when this is set.</p> <code>False</code> <code>force</code> <code>bool</code> <p>Whether to overwrite output files if they exist.</p> <code>False</code> Source code in <code>src/drim2p/convert/raw.py</code> <pre><code>def convert_raw(\n    source: pathlib.Path,\n    ini_path: pathlib.Path | None = None,\n    xml_path: pathlib.Path | None = None,\n    out: pathlib.Path | None = None,\n    recursive: bool = False,\n    include: str | None = None,\n    exclude: str | None = None,\n    compression: io.COMPRESSION | None = None,\n    compression_opts: int | None = None,\n    generate_timestamps: bool = False,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"Converts RAW data and metadata to HDF5.\n\n    Note that SOURCE can be either a single file or a directory. If it is a directory,\n    all the RAW files it contains will be converted.\n\n    If '--ini-path' is not provided, it will default to the same path as the source file\n    with the extension changed to '.ini'.\n    If '--xml-path' is not provided, it will default to the same path as the source file\n    with the extension changed to '.xml', and the 'XYT' ending changed to 'OME'. Note\n    the OME-XML path is optional if the INI file contains the OME-XML as an entry.\n\n    If `generate_timestamps` is set, a `.notes.txt` file with the same name as the RAW\n    file should also be present.\n\n    Args:\n        source (pathlib.Path):\n            Source file or directory to convert. If a directory, the default is to look\n            for RAW files inside of it without recursion.\n        ini_path (pathlib.Path | None, optional):\n            Path to the INI file containing metadata about SOURCE. This is ignored if\n            SOURCE is a directory.\n        xml_path (pathlib.Path | None, optional):\n            Path to the XML file containing metadata about SOURCE. This is ignored if\n            SOURCE is a directory.\n        out (pathlib.Path | None, optional):\n            Optional output directory for converted files.\n        recursive (bool, optional):\n            Whether to search directories recursively when looking for RAW files.\n        include (str | None, optional):\n            Include filters to apply when searching for RAW files. This supports\n            regular-expressions. Include filters are applied before any exclude filters.\n        exclude (str | None, optional):\n            Exclude filters to apply when searching for RAW files. This supports\n            regular-expressions. Exclude filters are applied after all include filters.\n        compression (io.COMPRESSION | None, optional): Compression algorithm to use.\n        compression_opts (int | None, optional):\n            Compression options to use with the given algorithm.\n        generate_timestamps (bool, optional):\n            Whether to generate timestamps from the notes entries of the RAW files. A\n            \".notes.txt\" file should be present along the RAW file when this is set.\n        force (bool, optional): Whether to overwrite output files if they exist.\n    \"\"\"\n    # Collect RAW file paths to convert\n    raw_paths = io.find_paths(source, [\".raw\"], include, exclude, recursive, True)\n\n    # If we are going to process at least a file, ensure the output directory exists\n    if len(raw_paths) &gt; 0 and out is not None:\n        # Only allow creating a directory inside an existing parent. We should only\n        # support creating a single directory, not a nested hierarchy as a single typo\n        # in a path can result in a lot of folders being created in a way a user might\n        # not expect.\n        try:\n            out.mkdir(exist_ok=True)\n        except FileNotFoundError:\n            _logger.exception(\n                f\"Neither provided output directory '{out}' nor its parent exist. \"\n                f\"Aborting.\"\n            )\n            return\n\n    # Ignore ini_path and xml_path if we are working with a directory\n    if source.is_dir():\n        ini_path = None\n        xml_path = None\n\n    for path in raw_paths:\n        # Shortcircuit early if we won't write\n        out_path = (\n            out / path.with_suffix(\".h5\").name\n            if out is not None\n            else path.with_suffix(\".h5\")\n        )\n        if out_path.exists() and not force:\n            _logger.info(\n                f\"Skipping '{path}' as it already exists and --force is not set.\"\n            )\n            continue\n\n        _logger.info(f\"Converting '{path}'.\")\n\n        # Retrieve INI metadata\n        ini_metadata_path = ini_path or path.with_suffix(\".ini\")\n        ini_metadata = {}\n        if ini_metadata_path.exists():\n            try:\n                ini_metadata = raw_io.parse_metadata_from_ini(\n                    ini_metadata_path, typed=True\n                )\n            except ValueError as e:\n                _logger.warning(e)\n        else:\n            _logger.debug(f\"No INI metadata found for '{path}'.\")\n\n        # Retrieve XML metadata\n        xml_string = None\n        if ini_metadata:\n            xml_string = ini_metadata.get(\"ome.xml.string\")\n            if xml_string is None:\n                _logger.debug(\n                    \"Failed to retrieve XML metadata from INI metadata. Trying to use \"\n                    \"the XML file directly.\"\n                )\n            else:\n                _logger.debug(\"Using XML string from INI file.\")\n\n        if xml_string is None:\n            xml_metadata_path = xml_path or _find_xml_path(path)\n            if xml_metadata_path is None or not xml_metadata_path.exists():\n                _logger.debug(f\"No XML metadata found for '{path}'.\")\n                _logger.error(\n                    f\"Failed to retrieve OME-XML metadata from INI file or directly \"\n                    f\"through XML file for '{path}', skipping RAW file. \"\n                    f\"To use the XML file, make sure it has the same file name as the \"\n                    f\"RAW file with the '.xml' or '.ome.xml' extension(s).\"\n                )\n                continue\n\n            _logger.debug(\"Using XML string from XML file.\")\n            xml_string = xml_metadata_path.open().read()\n\n        shape, dtype = raw_io.parse_metadata_from_ome(xml_string)\n\n        # Generate timestamps if requested\n        timestamps = None\n        if generate_timestamps:\n            timestamps = _generate_timestamps(path, ini_metadata)\n\n        # Convert RAW to numpy\n        _logger.debug(f\"Reading as array using metadata: {shape=}, {dtype=}.\")\n        array = raw_io.read_raw_as_numpy(path, shape, dtype)\n\n        # Output as HDF5\n        compression, compression_opts, shuffle = io.get_h5py_compression_parameters(\n            compression, compression_opts\n        )\n\n        _logger.debug(\n            f\"Writing HDF5 to '{out_path}' \"\n            f\"({compression=}, {compression_opts=}, {shuffle=}).\"\n        )\n        with h5py.File(out_path, \"w\") as handle:\n            dataset = handle.create_dataset(\n                io.ACQ_IMAGING_PATH,\n                data=array,\n                # Chunk per frame, same for writing but speeds up reading a lot\n                chunks=(1, *shape[1:]),\n                compression=compression,\n                compression_opts=compression_opts,\n                shuffle=shuffle,\n            )\n\n            for key, value in ini_metadata.items():\n                dataset.attrs[key] = value\n\n            if timestamps is not None:\n                handle.create_dataset(\n                    io.ACQ_TIMESTAMPS_PATH,\n                    data=timestamps,\n                    compression=compression,\n                    compression_opts=compression_opts,\n                    shuffle=shuffle,\n                )\n\n        _logger.info(f\"Finished converting '{path}'.\")\n</code></pre>"},{"location":"reference/API/drim2p/convert/raw/#drim2p.convert.raw.convert_raw_command","title":"<code>convert_raw_command(**kwargs)</code>","text":"<p>Converts RAW data and metadata to HDF5.</p> <p>Note that SOURCE can be either a single file or a directory. If it is a directory, all the RAW files it contains will be converted.</p> <p>If '--ini-path' is not provided, it will default to the same path as the source file with the extension changed to '.ini'. If '--xml-path' is not provided, it will default to the same path as the source file with the extension changed to '.xml', and the 'XYT' ending changed to 'OME'. Note the OME-XML path is optional if the INI file contains the OME-XML as an entry.</p> <p>If <code>generate_timestamps</code> is set, a <code>.notes.txt</code> file with the same name as the RAW file should also be present.</p> Source code in <code>src/drim2p/convert/raw.py</code> <pre><code>@click.command(\"raw\")\n@click.argument(\n    \"source\",\n    required=False,\n    type=click.Path(\n        exists=True,\n        file_okay=True,\n        dir_okay=True,\n        readable=True,\n        path_type=pathlib.Path,\n    ),\n    callback=cli_utils.noop_if_missing,\n)\n@click.option(\n    \"--ini-path\",\n    required=False,\n    type=click.Path(\n        exists=True,\n        file_okay=True,\n        dir_okay=False,\n        path_type=pathlib.Path,\n    ),\n    help=(\n        \"Path to the INI file containing metadata about SOURCE. \"\n        \"This is ignored if SOURCE is a directory.\"\n    ),\n)\n@click.option(\n    \"--xml-path\",\n    required=False,\n    type=click.Path(\n        exists=True,\n        file_okay=True,\n        dir_okay=False,\n        path_type=pathlib.Path,\n    ),\n    help=(\n        \"Path to the OME-XML file containing metadata about SOURCE. \"\n        \"This is ignored if SOURCE is a directory.\"\n    ),\n)\n@click.option(\n    \"-o\",\n    \"--out\",\n    required=False,\n    type=click.Path(\n        exists=False,\n        file_okay=False,\n        dir_okay=True,\n        writable=True,\n        path_type=pathlib.Path,\n    ),\n    help=(\n        \"Output directory in which to put the converted files. \"\n        \"Default is to output in the same directory as SOURCE.\"\n    ),\n)\n@click.option(\n    \"-r\",\n    \"--recursive\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to search directories recursively when looking for RAW files.\",\n)\n@click.option(\n    \"-i\",\n    \"--include\",\n    required=False,\n    default=None,\n    help=(\n        \"Include filters to apply when searching for RAW files. \"\n        \"This supports regular-expressions. Include filters are applied before any \"\n        \"exclude filters.\"\n    ),\n)\n@click.option(\n    \"-e\",\n    \"--exclude\",\n    required=False,\n    default=None,\n    help=(\n        \"Exclude filters to apply when searching for RAW files. \"\n        \"This supports regular-expressions. Exclude filters are applied after all \"\n        \"include filters.\"\n    ),\n)\n@click.option(\n    \"-c\",\n    \"--compression\",\n    required=False,\n    type=click.Choice(get_args(io.COMPRESSION), case_sensitive=False),\n    default=None,\n    callback=lambda _, __, x: x if x is None else x.lower(),\n    help=\"Compression algorithm to use.\",\n)\n@click.option(\n    \"--aggression\",\n    \"compression_opts\",\n    required=False,\n    type=click.IntRange(0, 9),\n    default=4,\n    help=(\n        \"Aggression level to use for GZIP compression. Lower means faster/worse \"\n        \"compression, higher means slower/better compression. Ignored if \"\n        \"'--compression' is not GZIP.\"\n    ),\n)\n@click.option(\n    \"--generate-timestamps\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to generate timestamps from the notes entries of the RAW files.\",\n)\n@click.option(\n    \"--force\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to overwrite output files if they exist.\",\n)\ndef convert_raw_command(**kwargs: Any) -&gt; None:\n    \"\"\"Converts RAW data and metadata to HDF5.\n\n    Note that SOURCE can be either a single file or a directory. If it is a directory,\n    all the RAW files it contains will be converted.\n\n    If '--ini-path' is not provided, it will default to the same path as the source file\n    with the extension changed to '.ini'.\n    If '--xml-path' is not provided, it will default to the same path as the source file\n    with the extension changed to '.xml', and the 'XYT' ending changed to 'OME'. Note\n    the OME-XML path is optional if the INI file contains the OME-XML as an entry.\n\n    If `generate_timestamps` is set, a `.notes.txt` file with the same name as the RAW\n    file should also be present.\n    \"\"\"\n    convert_raw(**kwargs)\n</code></pre>"},{"location":"reference/API/drim2p/convert/raw/#drim2p.convert.raw.generate_timestamps_for_note_entry","title":"<code>generate_timestamps_for_note_entry(entry, frame_count)</code>","text":"<p>Generates a timestamps series for a given notes entry and a frame count.</p> <p>Parameters:</p> Name Type Description Default <code>entry</code> <code>NotesEntry</code> <p>Entry for which to generate timestamps.</p> required <code>frame_count</code> <code>int</code> <p>Integer count of the frames for the given entry.</p> required <p>Returns:</p> Type Description <code>ndarray[Any, dtype[number]]</code> <p>A series of timestamps for each frame.</p> Source code in <code>src/drim2p/convert/raw.py</code> <pre><code>def generate_timestamps_for_note_entry(\n    entry: models.NotesEntry, frame_count: int\n) -&gt; np.ndarray[Any, np.dtype[np.number]]:\n    \"\"\"Generates a timestamps series for a given notes entry and a frame count.\n\n    Args:\n        entry (models.NotesEntry): Entry for which to generate timestamps.\n        frame_count (int): Integer count of the frames for the given entry.\n\n    Returns:\n        A series of timestamps for each frame.\n    \"\"\"\n    delta = entry.timedelta_ms\n    frame_spacing = delta / frame_count\n\n    return np.array([i * frame_spacing for i in range(frame_count)])\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/","title":"deltaf","text":""},{"location":"reference/API/drim2p/deltaf/#drim2p.deltaf.compute_dff","title":"<code>compute_dff(source, method='percentile', percentile=5, window_width=0, padding_mode='constant', constant_value=0, recursive=False, include=None, exclude=None, force=False)</code>","text":"<p>Computes \u0394F/F\u2080 for extracted signals.</p> <p>Input arrays should be 1- or 2D arrays, where the first dimension is the one along which to compute f\u2080.</p> <p>If given a rolling window width, f\u2080 is computed for each entry along the first dimension of the input array. For values around the edges (within half of window width), the array is padded using the provided method (default is padding with 0s). Because of this, choosing a window that is too large can produce some unexpected values far into the array.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Path</code> <p>Source file or directory to process. If a directory, the default is to look look for files inside of it without recursion.</p> required <code>method</code> <code>_F0Method</code> <p>Computation method for f\u2080.</p> <code>'percentile'</code> <code>percentile</code> <code>int</code> <p>Percentile to use when computing f\u2080 using the percentile method. Ignored if computing with a different method.</p> <code>5</code> <code>window_width</code> <code>int</code> <p>Rolling window width in frames to use when computing f\u2080. Pass 0 to disable it (default). If greater than 0, the window is used to compute a running value of f\u2080 for each timepoint of the input, with padding applied according to <code>padding_mode</code> around the edges. If greater than 0, the rolling window should be less than twice the size of the first dimension of the input minus 1.</p> <code>0</code> <code>padding_mode</code> <code>_PaddingMode</code> <p>Mode to use when padding the input. Ignored if 'window_width' is 0.</p> <code>'constant'</code> <code>constant_value</code> <code>int</code> <p>Constant value to use when padding using 'constant' mode. Ignored if 'padding_mode' is not 'constant'.</p> <code>0</code> <code>recursive</code> <code>bool</code> <p>Whether to search directories recursively when looking for files.</p> <code>False</code> <code>include</code> <code>str | None</code> <p>Include filters to apply when searching for files. This supports regular expressions. Include filters are applied before any exclude filters. They should be a semi-colon-separated string of filters (e.g., 'foo;bar' contains two filters, 'foo' and 'bar').</p> <code>None</code> <code>exclude</code> <code>str | None</code> <p>Exclude filters to apply when searching for files. This supports regular expressions. Exclude filters are applied after all include filters. They should be a semi-colon-separated string of filters (e.g., 'foo;bar' contains two filters, 'foo' and 'bar').</p> <code>None</code> <code>force</code> <code>bool</code> <p>Whether to overwrite output files if they exist.</p> <code>False</code> Source code in <code>src/drim2p/deltaf/__init__.py</code> <pre><code>def compute_dff(\n    source: pathlib.Path,\n    method: _F0Method = \"percentile\",\n    percentile: int = 5,\n    window_width: int = 0,\n    padding_mode: _PaddingMode = \"constant\",\n    constant_value: int = 0,\n    recursive: bool = False,\n    include: str | None = None,\n    exclude: str | None = None,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"Computes \u0394F/F\u2080 for extracted signals.\n\n    Input arrays should be 1- or 2D arrays, where the first dimension is the one along\n    which to compute f\u2080.\n\n    If given a rolling window width, f\u2080 is computed for each entry along the first\n    dimension of the input array. For values around the edges (within half of window\n    width), the array is padded using the provided method (default is padding with\n    0s). Because of this, choosing a window that is too large can produce some\n    unexpected values far into the array.\n\n    Args:\n        source (pathlib.Path):\n            Source file or directory to process. If a directory, the default is to look\n            look for files inside of it without recursion.\n        method (_F0Method, optional): Computation method for f\u2080.\n        percentile (int, optional):\n            Percentile to use when computing f\u2080 using the percentile method. Ignored if\n            computing with a different method.\n        window_width (int, optional):\n            Rolling window width in frames to use when computing f\u2080. Pass 0 to disable\n            it (default). If greater than 0, the window is used to compute a running\n            value of f\u2080 for each timepoint of the input, with padding applied according\n            to `padding_mode` around the edges. If greater than 0, the rolling window\n            should be less than twice the size of the first dimension of the input minus\n            1.\n        padding_mode (_PaddingMode, optional):\n            Mode to use when padding the input. Ignored if 'window_width' is 0.\n        constant_value (int, optional):\n            Constant value to use when padding using 'constant' mode. Ignored if\n            'padding_mode' is not 'constant'.\n        recursive (bool, optional):\n            Whether to search directories recursively when looking for files.\n        include (str | None, optional):\n            Include filters to apply when searching for files. This supports regular\n            expressions. Include filters are applied before any exclude filters. They\n            should be a semi-colon-separated string of filters (e.g., 'foo;bar' contains\n            two filters, 'foo' and 'bar').\n        exclude (str | None, optional):\n            Exclude filters to apply when searching for files. This supports regular\n            expressions. Exclude filters are applied after all include filters. They\n            should be a semi-colon-separated string of filters (e.g., 'foo;bar' contains\n            two filters, 'foo' and 'bar').\n        force (bool, optional): Whether to overwrite output files if they exist.\n    \"\"\"\n    for path in io.find_paths(source, [\".h5\"], include, exclude, recursive, True):\n        _logger.info(f\"Computing \u0394F/F\u2080 for '{path}'.\")\n        _logger.debug(f\"Opening handle for '{path}'.\")\n        handle = h5py.File(path, \"a\", locking=False)\n\n        # Retrieve signal group\n        roi_group = handle.get(io.EXT_SIGNAL_LIST_PATH)\n        neuropil_group = handle.get(io.EXT_NEUROPIL_PATH)\n        if roi_group is None:\n            _logger.error(\n                f\"Could not find group '{io.EXT_SIGNAL_LIST_PATH}' inside of '{path}'. \"\n                f\"Available groups at the root are: {list(handle)}. Skipping file.\"\n            )\n            continue\n\n        # Check for existing \u0394F/F\u2080\n        deltaf_roi_group = handle.get(io.DEL_SIGNAL_LIST_PATH)\n        if deltaf_roi_group is not None:\n            if not force:\n                _logger.info(\n                    f\"\u0394F/F\u2080 group already exists in '{path}' and 'force' was not set. \"\n                    f\"Skipping file.\"\n                )\n                continue\n\n            del handle[io.DEL_SIGNAL_LIST_PATH]\n\n        deltaf_roi_group = handle.create_group(io.DEL_SIGNAL_LIST_PATH)\n\n        # Process signals\n        _logger.debug(\"Computing \u0394F/F\u2080 for ROI signals.\")\n        for name in roi_group:\n            roi_signal = roi_group[name]\n\n            roi_dff = _compute_dff(\n                roi_signal,\n                method,\n                percentile,\n                window_width,\n                padding_mode,\n                constant_value,\n            )\n\n            deltaf_roi_group[name] = roi_dff\n\n        # Optionally do neuropils for QA\n        if neuropil_group is None:\n            _logger.debug(\n                \"No QA info found from the extracted path. Skipping \u0394F/F\u2080 computation \"\n                \"for neuropils.\"\n            )\n            _logger.info(\"Saved \u0394F/F\u2080.\")\n            return\n\n        with contextlib.suppress(KeyError):\n            del handle[io.DEL_NEUROPIL_PATH]\n        deltaf_neuropil_group = handle.create_group(io.DEL_NEUROPIL_PATH)\n\n        _logger.debug(\"Computing \u0394F/F\u2080 for neuropil signals.\")\n        for name in neuropil_group:\n            neuropil_signals = neuropil_group[name]\n\n            neuropil_dff = _compute_dff(\n                neuropil_signals,\n                method,\n                percentile,\n                window_width,\n                padding_mode,\n                constant_value,\n            )\n\n            deltaf_neuropil_group[name] = neuropil_dff\n\n        _logger.info(\"Saved \u0394F/F\u2080.\")\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/#drim2p.deltaf.compute_f0","title":"<code>compute_f0(array, method='percentile', percentile=5, window_width=0, padding_mode='constant', constant_value=0)</code>","text":"<p>Computes f\u2080 for a given array of signals.</p> <p>Parameters:</p> Name Type Description Default <code>array</code> <code>NDArray[Any]</code> <p>Array to compute f\u2080 for. The first dimension should be time.</p> required <code>method</code> <code>_F0Method</code> <p>Computation method for f\u2080.</p> <code>'percentile'</code> <code>percentile</code> <code>int</code> <p>Percentile to use when computing f\u2080 using the percentile method.</p> <code>5</code> <code>window_width</code> <code>int</code> <p>Rolling window width to use when computing f\u2080. Pass 0 to disable it. If greater than 0, the window is used to compute a running value of f\u2080 for each timepoint of the input, with padding applied according to 'padding_mode' around the edges. If greater than 0, the rolling window should be less than twice the size of the first dimension of the input minus 1.</p> <code>0</code> <code>padding_mode</code> <code>_PaddingMode</code> <p>Mode to use when padding the input. Ignored if 'window_width' is 0.</p> <code>'constant'</code> <code>constant_value</code> <code>int</code> <p>Constant value to use when padding using 'constant' mode. Ignored if 'window_width' is 0.</p> <code>0</code> <p>Returns:</p> Type Description <code>NDArray[Any]</code> <p>The F0 value for the input array. This is a 0D array if the input is 1D and</p> <code>NDArray[Any]</code> <p>no rolling window was provided. This is ND, where N is the dimensionality of</p> <code>NDArray[Any]</code> <p>the input, if a rolling window was provided.</p> <p>Raises:</p> Type Description <code>ArrayDimensionNotSupportedError</code> <p>If the input array is not 1- or 2D.</p> <code>OutOfRangePercentileError</code> <p>If the percentile is not between 0 and 100 inclusive.</p> <code>RollingWindowTooLargeError</code> <p>If the rolling window is larger than the first dimension of the input minus 1.</p> <code>UnknownMethodError</code> <p>If given an unknown method for computing F0.</p> <code>UnknownPaddingModeError</code> <p>If given an unknown padding mode.</p> Source code in <code>src/drim2p/deltaf/__init__.py</code> <pre><code>def compute_f0(\n    array: npt.NDArray[Any],\n    method: _F0Method = \"percentile\",\n    percentile: int = 5,\n    window_width: int = 0,\n    padding_mode: _PaddingMode = \"constant\",\n    constant_value: int = 0,\n) -&gt; npt.NDArray[Any]:\n    \"\"\"Computes f\u2080 for a given array of signals.\n\n    Args:\n        array (npt.NDArray[Any]):\n            Array to compute f\u2080 for. The first dimension should be time.\n        method (_F0Method, optional): Computation method for f\u2080.\n        percentile (int, optional):\n            Percentile to use when computing f\u2080 using the percentile method.\n        window_width (int, optional):\n            Rolling window width to use when computing f\u2080. Pass 0 to disable it. If\n            greater than 0, the window is used to compute a running value of f\u2080 for\n            each timepoint of the input, with padding applied according to\n            'padding_mode' around the edges. If greater than 0, the rolling window\n            should be less than twice the size of the first dimension of the input\n            minus 1.\n        padding_mode (_PaddingMode, optional):\n            Mode to use when padding the input. Ignored if 'window_width' is 0.\n        constant_value (int, optional):\n            Constant value to use when padding using 'constant' mode. Ignored if\n            'window_width' is 0.\n\n    Returns:\n        The F0 value for the input array. This is a 0D array if the input is 1D and\n        no rolling window was provided. This is ND, where N is the dimensionality of\n        the input, if a rolling window was provided.\n\n    Raises:\n        ArrayDimensionNotSupportedError: If the input array is not 1- or 2D.\n        OutOfRangePercentileError: If the percentile is not between 0 and 100 inclusive.\n        RollingWindowTooLargeError:\n            If the rolling window is larger than the first dimension of the input minus\n            1.\n        UnknownMethodError: If given an unknown method for computing F0.\n        UnknownPaddingModeError: If given an unknown padding mode.\n    \"\"\"\n    # Ensure data is 2D\n    got_1d_in = False\n    if len(array.shape) &gt; _2Dimensional or len(array.shape) &lt; _1Dimensional:\n        raise ArrayDimensionNotSupportedError(len(array.shape))\n    elif len(array.shape) == 1:\n        got_1d_in = True\n        array = array.reshape(-1, 1)\n\n    if method == \"percentile\":\n        if not 0 &lt;= percentile &lt;= 100:  # noqa: PLR2004\n            raise OutOfRangePercentileError(percentile)\n    # 'median' is a convenience method for percentile=50\n    elif method == \"median\":\n        method = \"percentile\"\n        percentile = 50\n    elif method not in get_args(_F0Method):\n        raise UnknownMethodError(method, get_args(_F0Method))\n\n    # No rolling window, compute single value along first axis and be done\n    if window_width &lt;= 0:\n        result = _compute_f0(array, method, percentile)\n\n        # Only squeeze when input was 1D (i.e., don't squeeze if we got 2D with one or\n        # more dimension(s) of size 1).\n        if got_1d_in:\n            result = result.squeeze()\n        return result\n\n    # We have a rolling window\n    # Ensure the rolling window is small enough\n    if window_width &gt; array.shape[0] * 2 - 1:\n        raise RollingWindowTooLargeError(window_width, array.shape[0])\n\n    # Ensure the window_width is odd so that it can be applied on integer indices\n    if window_width % 2 == 0:\n        window_width += 1\n\n    # Pad the input so that we can compute a value for all indices that are less\n    # than half of the window_width. We can't normally compute them as the window\n    # does not have enough information around the edges.\n    if padding_mode not in get_args(_PaddingMode):\n        raise UnknownPaddingModeError(padding_mode, get_args(_PaddingMode))\n    # Passing kwarg `constant_values` for methods other than \"constant\" raises a\n    # ValueError.\n    kwargs = {}\n    if padding_mode == \"constant\":\n        kwargs[\"constant_values\"] = constant_value\n\n    padded = np.pad(\n        array,\n        ((window_width // 2, window_width // 2), (0, 0)),\n        padding_mode,\n        **kwargs,\n    )  # type: ignore[call-overload]\n\n    # Make windows into the padded array. Using strides allows us to easily drag a\n    # window along the time dimension with shape (window_width, *rest_of_shape), one\n    # timepoint at at time.\n    windows = np.lib.stride_tricks.as_strided(\n        padded,\n        (array.shape[0], window_width, padded.shape[-1]),\n        # Duplicate the first stride so we slide the window one index in the first\n        # dimension at a time.\n        (padded.strides[0], *padded.strides),\n    )\n\n    # Compute and collect the results\n    results = np.empty(array.shape, np.float64)\n    for i, window in enumerate(windows):\n        results[i] = _compute_f0(window, method, percentile)\n\n    # Only squeeze when input was 1D (i.e., don't squeeze if we got 2D with one\n    # dimension of size 1).\n    if got_1d_in:\n        results = results.squeeze()\n    return results\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/#drim2p.deltaf.deltaf","title":"<code>deltaf(**kwargs)</code>","text":"<p>Computes \u0394F/F\u2080 for extracted signals.</p> <p>Input arrays should be 1- or 2D arrays, where the first dimension is the one along which to compute f\u2080.</p> <p>If given a rolling window width, f\u2080 is computed for each entry along the first dimension of the input array. For values around the edges (within half of window width), the array is padded using the provided method (default is padding with 0s). Because of this, choosing a window that is too large can produce some unexpected values far into the array.</p> Source code in <code>src/drim2p/deltaf/__init__.py</code> <pre><code>@click.command\n@click.argument(\n    \"source\",\n    required=False,\n    type=click.Path(\n        exists=True,\n        file_okay=True,\n        dir_okay=True,\n        readable=True,\n        path_type=pathlib.Path,\n    ),\n    callback=cli_utils.noop_if_missing,\n)\n@click.option(\n    \"-m\",\n    \"--method\",\n    required=False,\n    type=click.Choice(get_args(_F0Method)),\n    default=\"percentile\",\n    help=\"Computation method for f\u2080.\",\n)\n@click.option(\n    \"-p\",\n    \"--percentile\",\n    required=False,\n    type=click.INT,\n    default=5,\n    help=(\n        \"Percentile to use when computing f\u2080 using the 'percentile' method. Ignored if \"\n        \"computing with a different method.\"\n    ),\n)\n@click.option(\n    \"-w\",\n    \"--window-width\",\n    required=False,\n    type=click.INT,\n    default=0,\n    help=(\n        \"Rolling window width in frames to use when computing f\u2080. Pass 0 to disable \"\n        \"it (default). If greater than 0, the window is used to compute a running \"\n        \"value of f\u2080 for each timepoint of the input, with padding applied according \"\n        \"to '--padding' around the edges. If greater than 0, the rolling window should \"\n        \"be less than twice the size of the first dimension of the input minus 1.\"\n    ),\n)\n@click.option(\n    \"--padding\",\n    \"padding_mode\",\n    required=False,\n    type=click.Choice(get_args(_PaddingMode)),\n    default=\"constant\",\n    help=\"Mode to use when padding the input. Ignored if '--window-width' is 0.\",\n)\n@click.option(\n    \"--padding-value\",\n    \"constant_value\",\n    required=False,\n    type=click.INT,\n    default=0,\n    help=(\n        \"Constant value to use when padding using 'constant' mode. Ignored if \"\n        \"'--padding' is not 'constant'.\"\n    ),\n)\n@click.option(\n    \"-r\",\n    \"--recursive\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to search directories recursively when looking for files.\",\n)\n@click.option(\n    \"-i\",\n    \"--include\",\n    required=False,\n    default=None,\n    help=(\n        \"Include filters to apply when searching for files. This supports regular \"\n        \"expressions. Include filters are applied before any exclude filters. They \"\n        \"should be a semi-colon-separated string of filters (e.g., 'foo;bar' contains \"\n        \"two filters, 'foo' and 'bar').\"\n    ),\n)\n@click.option(\n    \"-e\",\n    \"--exclude\",\n    required=False,\n    default=None,\n    help=(\n        \"Exclude filters to apply when searching for files. This supports regular \"\n        \"expressions. Exclude filters are applied after all include filters. They \"\n        \"should be a semi-colon-separated string of filters (e.g., 'foo;bar' contains \"\n        \"two filters, 'foo' and 'bar').\"\n    ),\n)\n@click.option(\n    \"--force\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to overwrite output files if they exist.\",\n)\ndef deltaf(**kwargs: Any) -&gt; None:\n    \"\"\"Computes \u0394F/F\u2080 for extracted signals.\n\n    Input arrays should be 1- or 2D arrays, where the first dimension is the one along\n    which to compute f\u2080.\n\n    If given a rolling window width, f\u2080 is computed for each entry along the first\n    dimension of the input array. For values around the edges (within half of window\n    width), the array is padded using the provided method (default is padding with\n    0s). Because of this, choosing a window that is too large can produce some\n    unexpected values far into the array.\n    \"\"\"\n    compute_dff(**kwargs)\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/errors/","title":"errors","text":""},{"location":"reference/API/drim2p/deltaf/errors/#drim2p.deltaf.errors.ArrayDimensionNotSupportedError","title":"<code>ArrayDimensionNotSupportedError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Array is neither 1- or 2D.</p> <p>Parameters:</p> Name Type Description Default <code>dimension</code> <code>int</code> <p>Invalid dimensionality.</p> required Source code in <code>src/drim2p/deltaf/errors.py</code> <pre><code>class ArrayDimensionNotSupportedError(Exception):\n    \"\"\"Array is neither 1- or 2D.\n\n    Args:\n        dimension (int): Invalid dimensionality.\n    \"\"\"\n\n    def __init__(self, dimension: int) -&gt; None:\n        super().__init__(f\"Only 1- and 2D arrays are supported. Found: {dimension}D.\")\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/errors/#drim2p.deltaf.errors.InvalidPercentileError","title":"<code>InvalidPercentileError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Percentile is not a valid integer.</p> <p>Parameters:</p> Name Type Description Default <code>value</code> <code>Any</code> <p>Invalid percentile.</p> required Source code in <code>src/drim2p/deltaf/errors.py</code> <pre><code>class InvalidPercentileError(Exception):\n    \"\"\"Percentile is not a valid integer.\n\n    Args:\n        value (Any): Invalid percentile.\n    \"\"\"\n\n    def __init__(self, value: Any) -&gt; None:\n        super().__init__(f\"Cannot compute percentile when it is `{value}`.\")\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/errors/#drim2p.deltaf.errors.OutOfRangePercentileError","title":"<code>OutOfRangePercentileError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Percentile is outside of the range 0 to 100 inclusive.</p> <p>Parameters:</p> Name Type Description Default <code>percentile</code> <code>int</code> <p>Invalid percentile.</p> required Source code in <code>src/drim2p/deltaf/errors.py</code> <pre><code>class OutOfRangePercentileError(Exception):\n    \"\"\"Percentile is outside of the range 0 to 100 inclusive.\n\n    Args:\n        percentile (int): Invalid percentile.\n    \"\"\"\n\n    def __init__(self, percentile: int) -&gt; None:\n        super().__init__(\n            f\"Percentile should be between 0 and 100. Found: {percentile}. \"\n        )\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/errors/#drim2p.deltaf.errors.RollingWindowTooLargeError","title":"<code>RollingWindowTooLargeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Windows width is larger than twice the first dimension of the input minus one.</p> <p>Parameters:</p> Name Type Description Default <code>window_width</code> <code>int</code> <p>Invalid window width.</p> required <code>array_length</code> <code>int</code> <p>Length of the first dimension of the input array.</p> required Source code in <code>src/drim2p/deltaf/errors.py</code> <pre><code>class RollingWindowTooLargeError(Exception):\n    \"\"\"Windows width is larger than twice the first dimension of the input minus one.\n\n    Args:\n        window_width (int): Invalid window width.\n        array_length (int): Length of the first dimension of the input array.\n    \"\"\"\n\n    def __init__(self, window_width: int, array_length: int) -&gt; None:\n        super().__init__(\n            f\"Rolling window width should be at most twice the length of the first \"\n            f\"dimension of the input minus 1. Got '{window_width}' which is larger \"\n            f\"than {array_length * 2 - 1}.\"\n        )\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/errors/#drim2p.deltaf.errors.UnknownMethodError","title":"<code>UnknownMethodError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Given method for computing F0 is unknown.</p> <p>Parameters:</p> Name Type Description Default <code>method</code> <code>str</code> <p>Unknown method.</p> required <code>known</code> <code>Sequence[str]</code> <p>Known methods.</p> required Source code in <code>src/drim2p/deltaf/errors.py</code> <pre><code>class UnknownMethodError(Exception):\n    \"\"\"Given method for computing F0 is unknown.\n\n    Args:\n        method (str): Unknown method.\n        known (Sequence[str]): Known methods.\n    \"\"\"\n\n    def __init__(self, method: str, known: Sequence[str]) -&gt; None:\n        super().__init__(\n            f\"Unknown method: '{method}'. Valid methods are: {', '.join(known)}\"\n        )\n</code></pre>"},{"location":"reference/API/drim2p/deltaf/errors/#drim2p.deltaf.errors.UnknownPaddingModeError","title":"<code>UnknownPaddingModeError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Given padding mode is unknown.</p> <p>Parameters:</p> Name Type Description Default <code>padding_mode</code> <code>str</code> <p>Unknown padding mode.</p> required <code>known</code> <code>Sequence[str]</code> <p>Known padding modes.</p> required Source code in <code>src/drim2p/deltaf/errors.py</code> <pre><code>class UnknownPaddingModeError(Exception):\n    \"\"\"Given padding mode is unknown.\n\n    Args:\n        padding_mode (str): Unknown padding mode.\n        known (Sequence[str]): Known padding modes.\n    \"\"\"\n\n    def __init__(self, padding_mode: str, known: Sequence[str]) -&gt; None:\n        super().__init__(\n            f\"Unknown padding mode '{padding_mode}'. \"\n            f\"Valid modes are: {', '.join(known)}.\"\n        )\n</code></pre>"},{"location":"reference/API/drim2p/draw/","title":"draw","text":""},{"location":"reference/API/drim2p/draw/#drim2p.draw.draw","title":"<code>draw()</code>","text":"<p>Allows for drawing ROIs on HDF5 dataset.</p> Source code in <code>src/drim2p/draw/__init__.py</code> <pre><code>@click.group\ndef draw() -&gt; None:\n    \"\"\"Allows for drawing ROIs on HDF5 dataset.\"\"\"\n</code></pre>"},{"location":"reference/API/drim2p/draw/roi/","title":"roi","text":""},{"location":"reference/API/drim2p/draw/roi/#drim2p.draw.roi.draw_roi","title":"<code>draw_roi(source, template=None, dataset_name=io.MOT_IMAGING_PATH, projection_window=10, recursive=False, include=None, exclude=None, lazy=False, force=False)</code>","text":"<p>Starts a napari GUI to draw ROIs on HDF5 datasets.</p> <p>Note that SOURCE can be either a single file or a directory. If it is a directory, all the HDF5 files it contains will be queued for ROI drawing.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Path</code> <p>Source file or directory to convert. If a directory, the default is to look for HDF5 files inside of it without recursion.</p> required <code>template</code> <code>Path | None</code> <p>Path to the HDF5 file to read default ROIs from. When provided, any ROIs already present in the file will be used as the default ROIs for all source file. Use in conjunction with 'force' to overwrite any existing ROIs with the template ones.</p> <code>None</code> <code>dataset_name</code> <code>str</code> <p>Full path from the root to the HDF5 dataset to display.</p> <code>MOT_IMAGING_PATH</code> <code>projection_window</code> <code>int</code> <p>Window size to use for grouped Z projections.</p> <code>10</code> <code>recursive</code> <code>bool</code> <p>Whether to search directories recursively when looking for HDF5 files.</p> <code>False</code> <code>include</code> <code>str | None</code> <p>Include filters to apply when searching for HDF5 files. This supports regular-expressions. Include filters are applied before any exclude filters.</p> <code>None</code> <code>exclude</code> <code>str | None</code> <p>Exclude filters to apply when searching for HDF5 files. This supports regular-expressions. Exclude filters are applied after all include filters.</p> <code>None</code> <code>lazy</code> <code>bool</code> <p>Whether to lazily load the file. This will speed up the GUI startup time but will slow down any slicing when it is open. This will also disable the mean intensity projection.</p> <code>False</code> <code>force</code> <code>bool</code> <p>Whether to ovewrite ROIs if some are found in source. Otheriwse, ROIs are appended. Be careful when using this option as it will lead to all ROIs being deleted when opening a file.</p> <code>False</code> Source code in <code>src/drim2p/draw/roi.py</code> <pre><code>def draw_roi(\n    source: pathlib.Path,\n    template: pathlib.Path | None = None,\n    dataset_name: str = io.MOT_IMAGING_PATH,\n    projection_window: int = 10,\n    recursive: bool = False,\n    include: str | None = None,\n    exclude: str | None = None,\n    lazy: bool = False,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"Starts a napari GUI to draw ROIs on HDF5 datasets.\n\n    Note that SOURCE can be either a single file or a directory. If it is a directory,\n    all the HDF5 files it contains will be queued for ROI drawing.\n\n    Args:\n        source (pathlib.Path):\n            Source file or directory to convert. If a directory, the default is to look\n            for HDF5 files inside of it without recursion.\n        template (pathlib.Path | None, optional):\n            Path to the HDF5 file to read default ROIs from. When provided, any ROIs\n            already present in the file will be used as the default ROIs for all source\n            file. Use in conjunction with 'force' to overwrite any existing ROIs with\n            the template ones.\n        dataset_name (str, optional):\n            Full path from the root to the HDF5 dataset to display.\n        projection_window (int, optional): Window size to use for grouped Z projections.\n        recursive (bool, optional):\n            Whether to search directories recursively when looking for HDF5 files.\n        include (str | None, optional):\n            Include filters to apply when searching for HDF5 files. This supports\n            regular-expressions. Include filters are applied before any exclude filters.\n        exclude (str | None, optional):\n            Exclude filters to apply when searching for HDF5 files. This supports\n            regular-expressions. Exclude filters are applied after all include filters.\n        lazy (bool, optional):\n            Whether to lazily load the file. This will speed up the GUI startup time\n            but will slow down any slicing when it is open. This will also disable the\n            mean intensity projection.\n        force (bool, optional):\n            Whether to ovewrite ROIs if some are found in source. Otheriwse, ROIs are\n            appended. Be careful when using this option as it will lead to all ROIs\n            being deleted when opening a file.\n    \"\"\"\n    # Load template ROIs\n    template_rois: list[np.ndarray[Any, np.dtype[np.number]]] = []\n    template_roi_shape_types: list[str] = []\n    if template is not None:\n        with h5py.File(template) as handle:\n            _logger.debug(\"Loading ROIs from template.\")\n            template_rois, template_roi_shape_types = io.read_rois_and_shapes(handle)\n\n            if not template_rois:\n                # Stop early if the template is empty since this most likely means the\n                # user used the wrong option/file. We could also only abort when force\n                # is set.\n                _logger.error(\n                    f\"Could not load ROIs from provided template '{template}'. \"\n                    f\"Either there weren't any ROIs or the file structure was \"\n                    f\"unexpected. Ensure you have provided the correct template and \"\n                    f\"try again.\"\n                )\n                return\n\n    for path in io.find_paths(source, [\".h5\"], include, exclude, recursive, True):\n        _logger.info(f\"Opening '{path}'.\")\n        with h5py.File(path) as handle:\n            # Load the motion-corrected dataset\n            dataset = handle.get(dataset_name)\n            if dataset is None:\n                _logger.error(\n                    f\"Could not find group '{dataset_name}' in file '{path}'.\"\n                    f\"Available groups at the root are: {list(handle)}. Skipping file.\"\n                )\n                continue\n\n            # Convert to a Dask array so we can optionally, lazily load the array\n            array: da.Array = da.from_array(\n                dataset, chunks=(projection_window, *dataset.shape[1:])\n            )\n            # Make mean intensity grouped projections every projection_window frames\n            grouped: da.Array = array.map_blocks(\n                lambda x: da.mean(x, axis=0, keepdims=True),  # type: ignore[arg-type]\n                chunks=(1, *dataset.shape[1:]),\n            )  # type: ignore[call-arg]\n\n            # Make complete projection\n            projected: da.Array | None = None\n            if not lazy:\n                _logger.debug(\"Persisting arrays into memory.\")\n                array = array.persist()\n                # Redefining grouped is about twice a fast as simply persisting it if\n                # array was also persisted before it. Not exactly sure why.\n                grouped = array.map_blocks(\n                    lambda x: da.mean(x, axis=0, keepdims=True),  # type: ignore[arg-type]\n                    chunks=(1, *dataset.shape[1:]),\n                ).persist()  # type: ignore[call-arg]\n                # We could look for a pre-computed QA projection but we're loading the\n                # whole array into memory anyway so processing is pretty short.\n                projected = da.mean(grouped, axis=0).persist()\n\n            # Retrieve ROIs if they exist\n            rois: list[np.ndarray[Any, np.dtype[np.number]]] = []\n            roi_shape_types: list[str] = []\n            if not force:\n                rois, roi_shape_types = io.read_rois_and_shapes(handle)\n            else:\n                _logger.debug(\"'force' was set. Skipping looking for existing ROIs.\")\n\n            # Merge template and existing\n            rois += template_rois\n            roi_shape_types += template_roi_shape_types\n\n            # If a template is used on a file twice or more, it will generate\n            # duplicates.\n            rois, roi_shape_types = _remove_duplicates(rois, roi_shape_types)\n\n            # Update ROIs with modifications from GUI\n            rois = _start_roi_gui(grouped, projected, rois, roi_shape_types)\n\n            # ROI layer was deleted before GUI was closed, don't overwrite\n            if not rois:\n                _logger.debug(\n                    f\"'ROIs' layer was deleted. Skipping writing for '{path}'.\"\n                )\n                continue\n\n        with h5py.File(path, \"a\") as handle:\n            # Use this opportunity to save the mean projection for QA if we computed it\n            if projected is not None:\n                with contextlib.suppress(KeyError):\n                    del handle[io.MOT_MEAN_PROJECTION_PATH]\n\n                _logger.debug(\"Saving mean projection.\")\n                handle.create_dataset(io.MOT_MEAN_PROJECTION_PATH, data=projected)\n\n            # Add all ROIs to file. If force is not set, the ROIs will have already been\n            # retrieved above so we can just delete them in the file and re-add them\n            # with the new ones.\n            if handle.get(io.ROI_LIST_PATH) is not None:\n                _logger.debug(\"Deleting exisintg ROIs.\")\n                del handle[io.ROI_LIST_PATH]\n\n            _logger.debug(\"Saving ROIs.\")\n            roi_group = handle.create_group(io.ROI_LIST_PATH)\n            shape_types = []\n            for index, (roi, shape_type) in enumerate(\n                zip(rois.data, rois.shape_type, strict=True)\n            ):\n                # Discard line and path ROIs\n                if shape_type not in {\"rectangle\", \"ellipse\", \"polygon\"}:\n                    _logger.error(\n                        f\"ROI {index} has an unssuported shape type '{shape_type}'. \"\n                        f\"Discarding it.\"\n                    )\n                    continue\n\n                dataset = roi_group.create_dataset(f\"roi{index}\", data=roi)\n                # For good measure, add the type to the dataset directly in addition\n                # to the whole group later on. This makes it easier to inspect the HDF5\n                # file manually.\n                dataset.attrs[\"SHAPE_TYPE\"] = shape_type\n                shape_types.append(shape_type)\n\n            # Save ROI types\n            roi_group.attrs[\"SHAPE_TYPES\"] = shape_types\n</code></pre>"},{"location":"reference/API/drim2p/draw/roi/#drim2p.draw.roi.draw_roi_command","title":"<code>draw_roi_command(**kwargs)</code>","text":"<p>Starts a napari GUI to draw ROIs on HDF5 datasets.</p> <p>Note that SOURCE can be either a single file or a directory. If it is a directory, all the HDF5 files it contains will be queued for ROI drawing.</p> Source code in <code>src/drim2p/draw/roi.py</code> <pre><code>@click.command(\"roi\")\n@click.argument(\n    \"source\",\n    required=False,\n    type=click.Path(\n        exists=True,\n        file_okay=True,\n        dir_okay=True,\n        readable=True,\n        path_type=pathlib.Path,\n    ),\n    callback=cli_utils.noop_if_missing,\n)\n@click.option(\n    \"-t\",\n    \"--template\",\n    required=False,\n    type=click.Path(\n        exists=True, file_okay=True, dir_okay=False, path_type=pathlib.Path\n    ),\n    default=None,\n    help=(\n        \"Path to the HDF5 file to read default ROIs from. When provided, any ROIs \"\n        \"already present in the file will be used as the default ROIs for all SOURCE \"\n        \"file. Use in conjunction with '--force' to overwrite any existing ROIs with \"\n        \"the template ones.\"\n    ),\n)\n@click.option(\n    \"-d\",\n    \"--dataset\",\n    \"dataset_name\",\n    required=False,\n    default=io.MOT_IMAGING_PATH,\n    help=\"Full path from the root to the HDF5 dataset to display.\",\n)\n@click.option(\n    \"-w\",\n    \"--projection-window\",\n    required=False,\n    type=click.INT,\n    default=10,\n    help=\"Window size to use for grouped Z projections.\",\n)\n@click.option(\n    \"-r\",\n    \"--recursive\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to search directories recursively when looking for HDF5 files.\",\n)\n@click.option(\n    \"-i\",\n    \"--include\",\n    required=False,\n    default=None,\n    help=(\n        \"Include filters to apply when searching for HDF5 files. \"\n        \"This supports regular-expressions. Include filters are applied before any \"\n        \"exclude filters.\"\n    ),\n)\n@click.option(\n    \"-e\",\n    \"--exclude\",\n    required=False,\n    default=None,\n    help=(\n        \"Exclude filters to apply when searching for HDF5 files. \"\n        \"This supports regular-expressions. Exclude filters are applied after all \"\n        \"include filters.\"\n    ),\n)\n@click.option(\n    \"--lazy\",\n    required=False,\n    is_flag=True,\n    help=(\n        \"Whether to lazily load the file. This will speed up the GUI startup time but \"\n        \"will slow down any slicing when it is open. This will also disable the\"\n        \"mean intensity projection.\"\n    ),\n)\n@click.option(\n    \"--force\",\n    required=False,\n    is_flag=True,\n    help=(\n        \"Whether to ovewrite ROIs if some are found in SOURCE. \"\n        \"Otherwise, ROIs are appended. Be careful when using this option as it will \"\n        \"lead to all ROIs being deleted when opening a file.\"\n    ),\n)\ndef draw_roi_command(**kwargs: Any) -&gt; None:\n    \"\"\"Starts a napari GUI to draw ROIs on HDF5 datasets.\n\n    Note that SOURCE can be either a single file or a directory. If it is a directory,\n    all the HDF5 files it contains will be queued for ROI drawing.\n    \"\"\"\n    draw_roi(**kwargs)\n</code></pre>"},{"location":"reference/API/drim2p/extract/","title":"extract","text":""},{"location":"reference/API/drim2p/extract/#drim2p.extract.extract","title":"<code>extract()</code>","text":"<p>Extracts signals.</p> Source code in <code>src/drim2p/extract/__init__.py</code> <pre><code>@click.group()\ndef extract() -&gt; None:\n    \"\"\"Extracts signals.\"\"\"\n</code></pre>"},{"location":"reference/API/drim2p/extract/signal/","title":"signal","text":""},{"location":"reference/API/drim2p/extract/signal/#drim2p.extract.signal.extract_signal","title":"<code>extract_signal(source, group_by_regex=None, dataset_name=io.MOT_IMAGING_PATH, recursive=False, include=None, exclude=None, dont_abort_on_skipped_file=False, force=False)</code>","text":"<p>Extracts decontaminated signals from ROIs.</p> <p>Note that 'source' can be either a single file or a directory. If it is a directory, all the HDF5 files it contains will be converted.</p> <p>By default, all provided files are treated as separate sessions. In order to process files together, use 'group_by_regex' to group paths together based on a regular expression. If you wish to group all files together, pass an empty string as the regular expression.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Path</code> <p>Source file or directory to preprocess. If a directory, the default is to look for HDF5 files inside of it without recursion.</p> required <code>group_by_regex</code> <code>str</code> <p>Regular expression to use when grouping sources together. This results in the paths being preprocessed together based on the regex. This is ignored if source is a single file. Note that using this can lead to a very high memory usage depending on how many chunks needs to be loaded. Also note that for grouping to work, grouped files should have the same number of ROIs</p> <code>None</code> <code>dataset_name</code> <code>str</code> <p>Full path from the root to the HDF5 dataset to process.</p> <code>MOT_IMAGING_PATH</code> <code>recursive</code> <code>bool</code> <p>Whether to search directories recursively when looking for HDF5 files.</p> <code>False</code> <code>include</code> <code>str | None</code> <p>Include filters to apply when searching for HDF5 files. This supports regular-expressions. Include filters are applied before any exclude filters.</p> <code>None</code> <code>exclude</code> <code>str | None</code> <p>Exclude filters to apply when searching for HDF5 files. This supports regular-expressions. Exclude filters are applied after all include filters.</p> <code>None</code> <code>dont_abort_on_skipped_file</code> <code>bool</code> <p>Whether to keep working on a group if one or more of its paths is skipped for any reason (e.g., file was already preprocessed by '--force' is not set).</p> <code>False</code> <code>force</code> <code>bool</code> <p>Whether to overwrite output files if they exist.</p> <code>False</code> Source code in <code>src/drim2p/extract/signal.py</code> <pre><code>def extract_signal(\n    source: pathlib.Path,\n    group_by_regex: str | None = None,\n    dataset_name: str = io.MOT_IMAGING_PATH,\n    recursive: bool = False,\n    include: str | None = None,\n    exclude: str | None = None,\n    dont_abort_on_skipped_file: bool = False,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"Extracts decontaminated signals from ROIs.\n\n    Note that 'source' can be either a single file or a directory. If it is a directory,\n    all the HDF5 files it contains will be converted.\n\n    By default, all provided files are treated as separate sessions. In order to process\n    files together, use 'group_by_regex' to group paths together based on a regular\n    expression. If you wish to group all files together, pass an empty string as the\n    regular expression.\n\n    Args:\n        source (pathlib.Path):\n            Source file or directory to preprocess. If a directory, the default is to\n            look for HDF5 files inside of it without recursion.\n        group_by_regex (str, optional):\n            Regular expression to use when grouping sources together. This results in\n            the paths being preprocessed together based on the regex. This is ignored if\n            source is a single file. Note that using this can lead to a very high memory\n            usage depending on how many chunks needs to be loaded. Also note that for\n            grouping to work, grouped files should have the same number of ROIs\n        dataset_name (str, optional):\n            Full path from the root to the HDF5 dataset to process.\n        recursive (bool, optional):\n            Whether to search directories recursively when looking for HDF5 files.\n        include (str | None, optional):\n            Include filters to apply when searching for HDF5 files. This supports\n            regular-expressions. Include filters are applied before any exclude filters.\n        exclude (str | None, optional):\n            Exclude filters to apply when searching for HDF5 files. This supports\n            regular-expressions. Exclude filters are applied after all include filters.\n        dont_abort_on_skipped_file (bool, optional):\n            Whether to keep working on a group if one or more of its paths is skipped\n            for any reason (e.g., file was already preprocessed by '--force' is not\n            set).\n        force (bool, optional): Whether to overwrite output files if they exist.\n    \"\"\"\n    paths = io.find_paths(source, [\".h5\"], include, exclude, recursive, True)\n    groups = [[path] for path in paths]\n    if group_by_regex is not None:\n        groups = io.group_paths_by_regex(paths, group_by_regex)\n\n    for group in groups:\n        _extract_signal_for_group(\n            group, dataset_name, dont_abort_on_skipped_file, force\n        )\n</code></pre>"},{"location":"reference/API/drim2p/extract/signal/#drim2p.extract.signal.extract_signal_command","title":"<code>extract_signal_command(**kwargs)</code>","text":"<p>Extracts decontaminated signals from ROIs.</p> <p>Note that SOURCE can be either a single file or a directory. If it is a directory, all the HDF5 files it contains will be converted.</p> <p>By default, all provided files are treated as separate sessions. In order to process files together, use 'group-by-regex' to group paths together based on a regular expression. If you wish to group all files together, pass an empty string as the regular expression.</p> Source code in <code>src/drim2p/extract/signal.py</code> <pre><code>@click.command(\"signal\")\n@click.argument(\n    \"source\",\n    required=False,\n    type=click.Path(\n        exists=True,\n        file_okay=True,\n        dir_okay=True,\n        readable=True,\n        path_type=pathlib.Path,\n    ),\n    callback=cli_utils.noop_if_missing,\n)\n@click.option(\n    \"--group-by-regex\",\n    required=False,\n    default=None,\n    help=(\n        \"Regular expression to use when grouping SOURCEs together. This results in the \"\n        \"paths being preprocessed together based on the regex. This is ignored if \"\n        \"SOURCE is a single file. Note that using this can lead to a very high memory \"\n        \"usage depending on how many chunks needs to be loaded. Also note that for \"\n        \"grouping to work, grouped files should have the same number of ROIs.\"\n    ),\n)\n@click.option(\n    \"-d\",\n    \"--dataset\",\n    \"dataset_name\",\n    required=False,\n    default=io.MOT_IMAGING_PATH,\n    help=\"Full path from the root to the HDF5 dataset to process.\",\n)\n@click.option(\n    \"-r\",\n    \"--recursive\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to search directories recursively when looking for HDF5 files.\",\n)\n@click.option(\n    \"-i\",\n    \"--include\",\n    required=False,\n    default=None,\n    help=(\n        \"Include filters to apply when searching for HDF5 files. \"\n        \"This supports regular-expressions. Include filters are applied before any \"\n        \"exclude filters.\"\n    ),\n)\n@click.option(\n    \"-e\",\n    \"--exclude\",\n    required=False,\n    default=None,\n    help=(\n        \"Exclude filters to apply when searching for HDF5 files. \"\n        \"This supports regular-expressions. Exclude filters are applied after all \"\n        \"include filters.\"\n    ),\n)\n@click.option(\n    \"--dont-abort-on-skipped-file\",\n    required=False,\n    is_flag=True,\n    help=(\n        \"Whether to keep working on a group if one or more of its files is skipped for \"\n        \"any reason (e.g., file was already preprocessed by '--force' is not set).\"\n    ),\n)\n@click.option(\n    \"--force\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to overwrite output files if they exist.\",\n)\ndef extract_signal_command(**kwargs: Any) -&gt; None:\n    \"\"\"Extracts decontaminated signals from ROIs.\n\n    Note that SOURCE can be either a single file or a directory. If it is a directory,\n    all the HDF5 files it contains will be converted.\n\n    By default, all provided files are treated as separate sessions. In order to process\n    files together, use 'group-by-regex' to group paths together based on a regular\n    expression. If you wish to group all files together, pass an empty string as the\n    regular expression.\n    \"\"\"\n    extract_signal(**kwargs)\n</code></pre>"},{"location":"reference/API/drim2p/io/","title":"io","text":""},{"location":"reference/API/drim2p/io/#drim2p.io.collect_paths_from_extensions","title":"<code>collect_paths_from_extensions(root, extensions, recursive=False, strict=False)</code>","text":"<p>Collects paths from a root path based on extensions.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>Path</code> <p>Root path to start the search from. If this is a file, it is the only path for which the extension is matched.</p> required <code>extensions</code> <code>Iterable[str]</code> <p>Extensions to check against. By default, any file that contains one of these in its suffixes will be matched. See <code>strict</code> for a different behaviour.</p> required <code>recursive</code> <code>bool</code> <p>Whether to recursively visit directories when searching.</p> <code>False</code> <code>strict</code> <code>bool</code> <p>Whether to force checked files to only have a single suffix. By default, the checked extensions can appear anywhere in the suffix list of files.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>A list of the matched pats.</p> Source code in <code>src/drim2p/io/__init__.py</code> <pre><code>def collect_paths_from_extensions(\n    root: pathlib.Path,\n    extensions: Iterable[str],\n    recursive: bool = False,\n    strict: bool = False,\n) -&gt; list[pathlib.Path]:\n    \"\"\"Collects paths from a root path based on extensions.\n\n    Args:\n        root (pathlib.Path):\n            Root path to start the search from. If this is a file, it is the only path\n            for which the extension is matched.\n        extensions (Iterable[str]):\n            Extensions to check against. By default, any file that contains one of these\n            in its suffixes will be matched. See `strict` for a different behaviour.\n        recursive (bool, optional):\n            Whether to recursively visit directories when searching.\n        strict (bool, optional):\n            Whether to force checked files to only have a single suffix. By default, the\n            checked extensions can appear anywhere in the suffix list of files.\n\n    Returns:\n        A list of the matched pats.\n    \"\"\"\n\n    def have_at_least_one_common_element(\n        iterable1: Iterable[str], iterable2: Iterable[str]\n    ) -&gt; bool:\n        \"\"\"Returns whether at least one element is common to both iterables.\n\n        This matches each item of iterable1 against all those of iterable2 and computes\n        whether they are the same, then returns if at least one of the matches is True.\n\n        Returns:\n            Whether at least one element is common to both iterables.\n        \"\"\"\n        return any(x in iterable2 for x in iterable1)\n\n    collected = []\n\n    if root.is_file():\n        if have_at_least_one_common_element(\n            extensions, [root.suffix] if strict else root.suffixes\n        ):\n            collected = [root]\n        return collected\n\n    for path in root.iterdir():\n        if path.is_dir():\n            if not recursive:\n                continue\n\n            collected.extend(\n                collect_paths_from_extensions(path, extensions, recursive, strict)\n            )\n        elif have_at_least_one_common_element(\n            extensions, [path.suffix] if strict else path.suffixes\n        ):\n            collected.append(path)\n\n    return collected\n</code></pre>"},{"location":"reference/API/drim2p/io/#drim2p.io.filter_paths","title":"<code>filter_paths(paths, include=None, exclude=None, separator=';')</code>","text":"<p>Filters paths based on include and exclude strings.</p> <p>The order of operation first includes paths using the <code>include</code> filters then excludes paths using the <code>exclude</code> filters. If <code>include</code> is <code>None</code>, all paths are considered included before applying exclusion filters. If <code>exclude</code> is <code>None</code>, all paths included by <code>include</code> are returned. If both are <code>None</code>, all paths are returned.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>Iterable[Path]</code> <p>Paths to filter.</p> required <code>include</code> <code>str | None</code> <p>String of the include filters separated by <code>separator</code>.</p> <code>None</code> <code>exclude</code> <code>str | None</code> <p>String of the exclude filters separated by <code>separator</code>.</p> <code>None</code> <code>separator</code> <code>str</code> <p>A single-character separator used to separate different filters.</p> <code>';'</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>A list of the paths as filtered by the input filters.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; paths = [\n...     Path(\"path123\"),\n...     Path(\"path234\"),\n...     Path(\"path345\"),\n...     Path(\"path456\"),\n... ]\n&gt;&gt;&gt; include = \"1;2;3\"\n&gt;&gt;&gt; exclude = \"34\"\n</code></pre> <pre><code>&gt;&gt;&gt; filter_paths(paths, include=include)\n[Path('path123'), Path('path234'), Path('path345')]\n</code></pre> <pre><code>&gt;&gt;&gt; filter_paths(paths, exclude=exclude)\n[Path('path123'), Path('path456')]\n</code></pre> <pre><code>&gt;&gt;&gt; filter_paths(paths, include, exclude)\n[Path('path123')]\n</code></pre> Source code in <code>src/drim2p/io/__init__.py</code> <pre><code>def filter_paths(\n    paths: Iterable[pathlib.Path],\n    include: str | None = None,\n    exclude: str | None = None,\n    separator: str = \";\",\n) -&gt; list[pathlib.Path]:\n    \"\"\"Filters paths based on include and exclude strings.\n\n    The order of operation first includes paths using the `include` filters then\n    excludes paths using the `exclude` filters.\n    If `include` is `None`, all paths are considered included before applying exclusion\n    filters. If `exclude` is `None`, all paths included by `include` are returned. If\n    both are `None`, all paths are returned.\n\n    Args:\n        paths (Iterable[pathlib.Path]): Paths to filter.\n        include (str | None, optional):\n            String of the include filters separated by `separator`.\n        exclude (str | None, optional):\n            String of the exclude filters separated by `separator`.\n        separator (str, optional):\n            A single-character separator used to separate different filters.\n\n    Returns:\n        A list of the paths as filtered by the input filters.\n\n    Examples:\n        &gt;&gt;&gt; paths = [\n        ...     Path(\"path123\"),\n        ...     Path(\"path234\"),\n        ...     Path(\"path345\"),\n        ...     Path(\"path456\"),\n        ... ]\n        &gt;&gt;&gt; include = \"1;2;3\"\n        &gt;&gt;&gt; exclude = \"34\"\n\n        &gt;&gt;&gt; filter_paths(paths, include=include)\n        [Path('path123'), Path('path234'), Path('path345')]\n\n        &gt;&gt;&gt; filter_paths(paths, exclude=exclude)\n        [Path('path123'), Path('path456')]\n\n        &gt;&gt;&gt; filter_paths(paths, include, exclude)\n        [Path('path123')]\n    \"\"\"\n    # NO-OP if neither include nor exclude is set\n    if include is None and exclude is None:\n        return list(paths)\n\n    include = None if include is None else split_string(include, separator)\n    exclude = None if exclude is None else split_string(exclude, separator)\n\n    # First, filter which paths should be included based on `include` and `strict`\n    included = list(paths)\n    if include is not None:\n        included = []\n        for path in paths:\n            for filter_ in include:\n                if re.findall(filter_, str(path)):\n                    included.append(path)\n                    break\n\n    # Then, exclude any path previously selected if it matches an `exclude`\n    filtered = included\n    if exclude is not None:\n        filtered = []\n        for path in included:\n            for filter_ in exclude:\n                if re.findall(filter_, str(path)):\n                    break\n                filtered.append(path)\n\n    return filtered\n</code></pre>"},{"location":"reference/API/drim2p/io/#drim2p.io.find_paths","title":"<code>find_paths(root, extensions, include=None, exclude=None, recursive=False, strict=False)</code>","text":"<p>Collects and filters paths found in a directory.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>Path</code> <p>Path to the root path. If this is a file, it is the only file filtered. If it is a directory, files are collected then filtered from it. If 'recursive' is set, it is traversed recursively.</p> required <code>extensions</code> <code>Iterable[str]</code> <p>Extensions to check against. By default, any file that contains one of these in its suffixes will be matched. See <code>strict</code> for a different behaviour.</p> required <code>include</code> <code>str | None</code> <p>String of the include filters separated by <code>separator</code>.</p> <code>None</code> <code>exclude</code> <code>str | None</code> <p>String of the exclude filters separated by <code>separator</code>.</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Whether to recursively visit directories when searching.</p> <code>False</code> <code>strict</code> <code>bool</code> <p>Whether to force checked files to only have a single suffix. By default, the checked extensions can appear anywhere in the suffix list of files.</p> <code>False</code> <p>Returns:</p> Type Description <code>list[Path]</code> <p>A list of the paths collected and after filtering.</p> Source code in <code>src/drim2p/io/__init__.py</code> <pre><code>def find_paths(\n    root: pathlib.Path,\n    extensions: Iterable[str],\n    include: str | None = None,\n    exclude: str | None = None,\n    recursive: bool = False,\n    strict: bool = False,\n) -&gt; list[pathlib.Path]:\n    \"\"\"Collects and filters paths found in a directory.\n\n    Args:\n        root (pathlib.Path):\n            Path to the root path. If this is a file, it is the only file filtered. If\n            it is a directory, files are collected then filtered from it. If 'recursive'\n            is set, it is traversed recursively.\n        extensions (Iterable[str]):\n            Extensions to check against. By default, any file that contains one of these\n            in its suffixes will be matched. See `strict` for a different behaviour.\n        include (str | None, optional):\n            String of the include filters separated by `separator`.\n        exclude (str | None, optional):\n            String of the exclude filters separated by `separator`.\n        recursive (bool, optional):\n            Whether to recursively visit directories when searching.\n        strict (bool, optional):\n            Whether to force checked files to only have a single suffix. By default, the\n            checked extensions can appear anywhere in the suffix list of files.\n\n    Returns:\n        A list of the paths collected and after filtering.\n    \"\"\"\n    _logger.debug(\n        f\"Collecting files (extensions: {', '.join(extensions)} - include: {include} - \"\n        f\"exclude: {exclude}).\"\n    )\n\n    paths = [root]\n    if root.is_dir():\n        paths = collect_paths_from_extensions(root, extensions, recursive, strict)\n\n    paths = filter_paths(paths, include, exclude)\n\n    _logger.debug(f\"Collected {len(paths)} paths.\")\n\n    return paths\n</code></pre>"},{"location":"reference/API/drim2p/io/#drim2p.io.get_h5py_compression_parameters","title":"<code>get_h5py_compression_parameters(compression, compression_opts=None)</code>","text":"<p>Returns compression parameters for the given compression.</p> <p>Parameters:</p> Name Type Description Default <code>compression</code> <code>COMPRESSION | None</code> <p>Compression algorithm to use.</p> required <code>compression_opts</code> <code>int | None</code> <p>Compression algorithm options.</p> <code>None</code> <p>Returns:</p> Type Description <code>COMPRESSION | None</code> <p>A tuple of (compression, compression_opts, shuffle) where <code>compression</code> is a</p> <code>int | None</code> <p>valid compression value for <code>h5py.Group.create_dataset</code>, acompression_optsa is</p> <code>bool</code> <p>a valid aggression level for 'gzip' compression and <code>None</code> otherwise, and</p> <code>tuple[COMPRESSION | None, int | None, bool]</code> <p><code>shuffle</code> is whether to do byte-shuffling (only enabled for 'lzf' compression).</p> <p>Raises:</p> Type Description <code>UnknownCompressionError</code> <p>If the compression is not supported.</p> Source code in <code>src/drim2p/io/__init__.py</code> <pre><code>def get_h5py_compression_parameters(\n    compression: COMPRESSION | None, compression_opts: int | None = None\n) -&gt; tuple[COMPRESSION | None, int | None, bool]:\n    \"\"\"Returns compression parameters for the given compression.\n\n    Args:\n        compression (COMPRESSION | None): Compression algorithm to use.\n        compression_opts (int | None, optional): Compression algorithm options.\n\n    Returns:\n        A tuple of (compression, compression_opts, shuffle) where `compression` is a\n        valid compression value for `h5py.Group.create_dataset`, acompression_optsa is\n        a valid aggression level for 'gzip' compression and `None` otherwise, and\n        `shuffle` is whether to do byte-shuffling (only enabled for 'lzf' compression).\n\n    Raises:\n        UnknownCompressionError: If the compression is not supported.\n    \"\"\"\n    if compression is None:\n        compression_opts = None\n        shuffle = False\n    elif compression == \"gzip\":\n        compression_opts = compression_opts or 4\n        shuffle = False\n    elif compression == \"lzf\":\n        compression_opts = None\n        shuffle = True\n    else:\n        raise UnknownCompressionError(compression, (*get_args(COMPRESSION), None))\n\n    return compression, compression_opts, shuffle\n</code></pre>"},{"location":"reference/API/drim2p/io/#drim2p.io.group_paths_by_regex","title":"<code>group_paths_by_regex(paths, group_by_regex)</code>","text":"<p>Groups paths based on the match of <code>group_by_regex</code> against their stems.</p> <p>Paths that do not contain the regex are put in their own size 1 group.</p> <p>Parameters:</p> Name Type Description Default <code>paths</code> <code>list[Path]</code> <p>Paths to group.</p> required <code>group_by_regex</code> <code>str</code> <p>Regex to use when matching.</p> required <p>Returns:</p> Type Description <code>list[list[Path]]</code> <p>A list of path groups. Groups are guaranteed to have at least one element.</p> Source code in <code>src/drim2p/io/__init__.py</code> <pre><code>def group_paths_by_regex(\n    paths: list[pathlib.Path], group_by_regex: str\n) -&gt; list[list[pathlib.Path]]:\n    \"\"\"Groups paths based on the match of `group_by_regex` against their stems.\n\n    Paths that do not contain the regex are put in their own size 1 group.\n\n    Args:\n        paths (list[pathlib.Path]): Paths to group.\n        group_by_regex (str): Regex to use when matching.\n\n    Returns:\n        A list of path groups. Groups are guaranteed to have at least one element.\n    \"\"\"\n    matches = [re.findall(group_by_regex, path.stem) for path in paths]\n    groups: dict[str, list[pathlib.Path]] = {}\n    for match, path in zip(matches, paths, strict=True):\n        if len(match) == 0:\n            # If no matches found, default to a group of size 1 with the current path\n            match.append(path.stem)\n        match = match[0]  # noqa: PLW2901\n\n        groups[match] = [*groups.get(match, []), path]\n\n    return list(groups.values())\n</code></pre>"},{"location":"reference/API/drim2p/io/#drim2p.io.read_rois_and_shapes","title":"<code>read_rois_and_shapes(root)</code>","text":"<p>Reads ROI arrays and shapes from an HDF5 group.</p> <p>Parameters:</p> Name Type Description Default <code>root</code> <code>Group</code> <p>File handle of the root group.</p> required <p>Returns:</p> Type Description <code>list[ndarray[Any, dtype[number]]]</code> <p>A tuple of (rois, shapes) where <code>rois</code> is a list of NumPy arrays containing the</p> <code>list[str]</code> <p>vertices of the ROIs (of shape (X, 2) where X is the number of ROIs), and</p> <code>tuple[list[ndarray[Any, dtype[number]]], list[str]]</code> <p><code>shapes</code> is a list of string values for the shapes of the ROIs.</p> Source code in <code>src/drim2p/io/__init__.py</code> <pre><code>def read_rois_and_shapes(\n    root: h5py.Group,\n) -&gt; tuple[list[np.ndarray[Any, np.dtype[np.number]]], list[str]]:\n    \"\"\"Reads ROI arrays and shapes from an HDF5 group.\n\n    Args:\n        root (h5py.Group): File handle of the root group.\n\n    Returns:\n        A tuple of (rois, shapes) where `rois` is a list of NumPy arrays containing the\n        vertices of the ROIs (of shape (X, 2) where X is the number of ROIs), and\n        `shapes` is a list of string values for the shapes of the ROIs.\n    \"\"\"\n    rois: list[np.ndarray[Any, np.dtype[np.number]]] = []\n    roi_shape_types: list[str] = []\n\n    try:\n        roi_group = root[ROI_LIST_PATH]\n    except KeyError:\n        _logger.debug(\"No ROIs found.\")\n        return rois, roi_shape_types\n\n    _logger.debug(\"Found existing ROIs.\")\n\n    rois = [roi[:] for roi in roi_group.values()]\n    roi_shape_types = roi_group.attrs.get(\"SHAPE_TYPES\")\n    if roi_shape_types is not None and len(rois) == roi_shape_types.shape[0]:\n        roi_shape_types = roi_shape_types[:].astype(str).tolist()\n    else:\n        _logger.error(\"Failed to retrieve ROIs shape types. Assuming all polygons.\")\n        roi_shape_types = [\"polygon\"] * len(rois)\n\n    return rois, roi_shape_types\n</code></pre>"},{"location":"reference/API/drim2p/io/#drim2p.io.split_string","title":"<code>split_string(string, separator=';')</code>","text":"<p>Splits a string on non-escaped <code>separator</code> occurrences.</p> <p>Parameters:</p> Name Type Description Default <code>string</code> <code>str</code> <p>String to split.</p> required <code>separator</code> <code>str</code> <p>A single-character separator to split on.</p> <code>';'</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list containing the substrings after splitting.</p> <p>Raises:</p> Type Description <code>SeparatorTooLongError</code> <p>If the separator is longer than a single character.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; split_string(\"foo;bar\")\n['foo', 'bar']\n</code></pre> <pre><code>&gt;&gt;&gt; split_string(r\"foo;b\\;ar\")\n['foo', 'b\\\\;ar']  # Note that printing the second item shows 'b\\;ar'\n</code></pre> <pre><code>&gt;&gt;&gt; split_string(\"foo bar foo\\ bar\", \" \")\n['foo', 'bar', 'foo\\\\;bar']\n</code></pre> Source code in <code>src/drim2p/io/__init__.py</code> <pre><code>def split_string(string: str, separator: str = \";\") -&gt; list[str]:\n    r\"\"\"Splits a string on non-escaped `separator` occurrences.\n\n    Args:\n        string (str): String to split.\n        separator (str, optional): A single-character separator to split on.\n\n    Returns:\n        A list containing the substrings after splitting.\n\n    Raises:\n        SeparatorTooLongError: If the separator is longer than a single character.\n\n    Examples:\n        &gt;&gt;&gt; split_string(\"foo;bar\")\n        ['foo', 'bar']\n\n        &gt;&gt;&gt; split_string(r\"foo;b\\;ar\")\n        ['foo', 'b\\\\;ar']  # Note that printing the second item shows 'b\\;ar'\n\n        &gt;&gt;&gt; split_string(\"foo bar foo\\ bar\", \" \")\n        ['foo', 'bar', 'foo\\\\;bar']\n    \"\"\"\n    if len(separator) &gt; 1:\n        raise SeparatorTooLongError(separator)\n\n    return re.split(\n        rf\"(?&lt;!(?&lt;!\\\\)\\\\){separator}\", string\n    )  # Only split on separators that are not escaped, while allowing \"\\\\{separator}\"\n</code></pre>"},{"location":"reference/API/drim2p/io/errors/","title":"errors","text":""},{"location":"reference/API/drim2p/io/errors/#drim2p.io.errors.NoINISectionsFoundError","title":"<code>NoINISectionsFoundError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>INI file did not contain any section ([DEFAULT] excepted).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the INI file.</p> required Source code in <code>src/drim2p/io/errors.py</code> <pre><code>class NoINISectionsFoundError(Exception):\n    \"\"\"INI file did not contain any section ([DEFAULT] excepted).\n\n    Args:\n        path (pathlib.Path): Path to the INI file.\n    \"\"\"\n\n    def __init__(self, path: pathlib.Path) -&gt; None:\n        super().__init__(f\"Failed to parse INI metadata: no sections found. ({path})\")\n</code></pre>"},{"location":"reference/API/drim2p/io/errors/#drim2p.io.errors.SeparatorTooLongError","title":"<code>SeparatorTooLongError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Given separator is longer than a single character.</p> <p>Parameters:</p> Name Type Description Default <code>separator</code> <code>str</code> <p>Separator received.</p> required Source code in <code>src/drim2p/io/errors.py</code> <pre><code>class SeparatorTooLongError(Exception):\n    \"\"\"Given separator is longer than a single character.\n\n    Args:\n        separator (str): Separator received.\n    \"\"\"\n\n    def __init__(self, separator: str) -&gt; None:\n        super().__init__(f\"Separator should be a single character. Found: {separator}.\")\n</code></pre>"},{"location":"reference/API/drim2p/io/errors/#drim2p.io.errors.TooManyINISectionsFoundError","title":"<code>TooManyINISectionsFoundError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>INI file contained too many sections ([DEFAULT] excepted).</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the INI file.</p> required Source code in <code>src/drim2p/io/errors.py</code> <pre><code>class TooManyINISectionsFoundError(Exception):\n    \"\"\"INI file contained too many sections ([DEFAULT] excepted).\n\n    Args:\n        path (pathlib.Path): Path to the INI file.\n    \"\"\"\n\n    def __init__(self, path: pathlib.Path, sections: Sequence[str]) -&gt; None:\n        super().__init__(\n            f\"Failed to parse INI metadata: too many sections found. Only a single \"\n            f\"section (other than [DEFAULT]) is supported. \"\n            f\"Found: {' '.join(sections)}. ({path})\"\n        )\n</code></pre>"},{"location":"reference/API/drim2p/io/errors/#drim2p.io.errors.UnknownCompressionError","title":"<code>UnknownCompressionError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Requested compression is unknown.</p> <p>Parameters:</p> Name Type Description Default <code>compression</code> <code>str</code> <p>Compression requested.</p> required <code>known</code> <code>Sequence[str]</code> <p>Known compression values.</p> required Source code in <code>src/drim2p/io/errors.py</code> <pre><code>class UnknownCompressionError(Exception):\n    \"\"\"Requested compression is unknown.\n\n    Args:\n        compression (str): Compression requested.\n        known (Sequence[str]): Known compression values.\n    \"\"\"\n\n    def __init__(self, compression: str, known: Sequence[str]) -&gt; None:\n        super().__init__(\n            f\"Unknown compression: '{compression}'. \"\n            f\"Valid compression algorithms are: {', '.join(known)}\"\n        )\n</code></pre>"},{"location":"reference/API/drim2p/io/raw/","title":"raw","text":""},{"location":"reference/API/drim2p/io/raw/#drim2p.io.raw.NOTES_ENTRY_PATTERN","title":"<code>NOTES_ENTRY_PATTERN = re.compile('^-+$\\\\n((?:.|\\\\n)+?)\\\\n^-+$\\\\n', flags=re.MULTILINE)</code>  <code>module-attribute</code>","text":"<p>Pattern of a notes entry. It consists of lines of text between two lines of '-'s.</p>"},{"location":"reference/API/drim2p/io/raw/#drim2p.io.raw.parse_ini_config_as_typed","title":"<code>parse_ini_config_as_typed(config)</code>","text":"<p>Parses a dictionary of INI key-value pairs and returns a typed version.</p> <p>Note, this assumes that the config dictionary was read using <code>configparser</code> and that all values are strictly coercible to integers, floats, booleans, or strings.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict[str, str]</code> <p>Config dictionary to parse.</p> required <p>Returns:</p> Type Description <code>dict[str, int | float | bool | str]</code> <p>The typed version of the dictionary.</p> Source code in <code>src/drim2p/io/raw.py</code> <pre><code>def parse_ini_config_as_typed(\n    config: dict[str, str],\n) -&gt; dict[str, int | float | bool | str]:\n    \"\"\"Parses a dictionary of INI key-value pairs and returns a typed version.\n\n    Note, this assumes that the config dictionary was read using `configparser` and\n    that all values are strictly coercible to integers, floats, booleans, or strings.\n\n    Args:\n        config (dict[str, str]): Config dictionary to parse.\n\n    Returns:\n        The typed version of the dictionary.\n    \"\"\"\n    typed: dict[str, int | float | bool | str] = {}\n\n    for key, value in config.items():\n        # Integers\n        if value.isnumeric():\n            typed[key] = int(value)\n            continue\n\n        # Floats\n        if re.fullmatch(r\"^[0-9.-]+$\", value):\n            typed[key] = float(value)\n            continue\n\n        # Booleans\n        if value in {\"FALSE\", \"TRUE\"}:\n            typed[key] = value == \"TRUE\"\n            continue\n\n        # Strings\n        typed[key] = value[1:-1]\n\n    return typed\n</code></pre>"},{"location":"reference/API/drim2p/io/raw/#drim2p.io.raw.parse_metadata_from_ini","title":"<code>parse_metadata_from_ini(ini_path, typed=False)</code>","text":"<p>Parses metadata from an INI file.</p> <p>Parameters:</p> Name Type Description Default <code>ini_path</code> <code>Path</code> <p>Path to the INI file.</p> required <code>typed</code> <code>bool</code> <p>Whether to parse the values as typed.</p> <code>False</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>The config dictionary, as either <code>dict[str, str]</code> if untyped, or</p> <code>dict[str, Any]</code> <p><code>dict[str, Any]</code> if typed.</p> <p>Raises:</p> Type Description <code>NoINISectionsFoundError</code> <p>If the INI file does not contain any sections ([DEFAULT] excluded).</p> <code>TooManyINISectionsFoundError</code> <p>If the INI file contains more than one section ([DEFAULT] excluded).</p> Source code in <code>src/drim2p/io/raw.py</code> <pre><code>def parse_metadata_from_ini(\n    ini_path: pathlib.Path, typed: bool = False\n) -&gt; dict[str, Any]:\n    \"\"\"Parses metadata from an INI file.\n\n    Args:\n        ini_path (pathlib.Path): Path to the INI file.\n        typed (bool, optional): Whether to parse the values as typed.\n\n    Returns:\n        The config dictionary, as either `dict[str, str]` if untyped, or\n        `dict[str, Any]` if typed.\n\n    Raises:\n        NoINISectionsFoundError:\n            If the INI file does not contain any sections ([DEFAULT] excluded).\n        TooManyINISectionsFoundError:\n            If the INI file contains more than one section ([DEFAULT] excluded).\n    \"\"\"\n    parser = configparser.ConfigParser()\n    parser.read(ini_path)\n\n    sections = parser.sections()\n    if len(sections) &lt; 1:\n        raise NoINISectionsFoundError(ini_path)\n    elif len(sections) &gt; 1:\n        raise TooManyINISectionsFoundError(ini_path, sections)\n    section = sections[0]\n\n    config = dict(parser[section])\n    return config if not typed else parse_ini_config_as_typed(config)\n</code></pre>"},{"location":"reference/API/drim2p/io/raw/#drim2p.io.raw.parse_metadata_from_ome","title":"<code>parse_metadata_from_ome(xml)</code>","text":"<p>Parses type and shape information of a RAW file from its OME-XML metadata.</p> <p>Parameters:</p> Name Type Description Default <code>xml</code> <code>Path | str</code> <p>Path to the OME-XML metadata or a string of the metadata.</p> required <p>Returns:</p> Type Description <code>tuple[int, int, int]</code> <p>A tuple of the (<code>shape</code>, <code>dtype``) of the RAW file, where</code>shape` is the shape</p> <code>dtype[number]</code> <p>in ZYX order, and <code>dtype</code> is the numpy data type with the correct byte order.</p> Source code in <code>src/drim2p/io/raw.py</code> <pre><code>def parse_metadata_from_ome(\n    xml: pathlib.Path | str,\n) -&gt; tuple[tuple[int, int, int], np.dtype[np.number]]:\n    \"\"\"Parses type and shape information of a RAW file from its OME-XML metadata.\n\n    Args:\n        xml (pathlib.Path | str):\n            Path to the OME-XML metadata or a string of the metadata.\n\n    Returns:\n        A tuple of the (`shape`, `dtype``) of the RAW file, where `shape` is the shape\n        in ZYX order, and `dtype` is the numpy data type with the correct byte order.\n    \"\"\"\n    # Lazy time-consuming import\n    import ome_types\n\n    # Silence `UserWarning`s for potentially invalid IDs that are automatically cast\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=UserWarning)\n        ome = ome_types.from_xml(xml)\n    pixels = ome.images[0].pixels\n\n    shape = pixels.size_t, pixels.size_y, pixels.size_x\n    dtype = np.dtype(pixels.type.numpy_dtype).newbyteorder(\n        \"&gt;\" if pixels.big_endian else \"&lt;\"\n    )\n\n    return shape, dtype\n</code></pre>"},{"location":"reference/API/drim2p/io/raw/#drim2p.io.raw.parse_notes_entries","title":"<code>parse_notes_entries(text)</code>","text":"<p>Parses notes entries from a text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Text containing the notes entries to parse.</p> required <p>Returns:</p> Type Description <code>list[NotesEntry]</code> <p>A list of entries as <code>models.NotesEntry</code>s.</p> Source code in <code>src/drim2p/io/raw.py</code> <pre><code>def parse_notes_entries(text: str) -&gt; list[models.NotesEntry]:\n    \"\"\"Parses notes entries from a text.\n\n    Args:\n        text (str): Text containing the notes entries to parse.\n\n    Returns:\n        A list of entries as `models.NotesEntry`s.\n    \"\"\"\n    entry_strings = re.findall(NOTES_ENTRY_PATTERN, text)\n\n    entries = []\n    for string in entry_strings:\n        start_time, _, file_path, *_, end_time = string.split(\"\\n\")\n\n        entries.append(\n            models.NotesEntry(\n                start_time=datetime.datetime.fromisoformat(start_time),\n                file_path=pathlib.Path(file_path),\n                end_time=datetime.datetime.fromisoformat(end_time),\n            )\n        )\n\n    return entries\n</code></pre>"},{"location":"reference/API/drim2p/io/raw/#drim2p.io.raw.read_raw_as_numpy","title":"<code>read_raw_as_numpy(path, shape, dtype)</code>","text":"<p>Reads a RAW file from disk and returns it as a numpy array.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path</code> <p>Path to the RAW file.</p> required <code>shape</code> <code>tuple[int, ...]</code> <p>Shape of the RAW file.</p> required <code>dtype</code> <code>dtype[number]</code> <p>Data type of the RAW file with the correct endianness.</p> required <p>Returns:</p> Type Description <code>ndarray[Any, dtype[number]]</code> <p>A numpy array made from the RAW data as <code>dtype</code> type and reshaped to <code>shape</code>.</p> Source code in <code>src/drim2p/io/raw.py</code> <pre><code>def read_raw_as_numpy(\n    path: pathlib.Path,\n    shape: tuple[int, ...],\n    dtype: np.dtype[np.number],\n) -&gt; np.ndarray[Any, np.dtype[np.number]]:\n    \"\"\"Reads a RAW file from disk and returns it as a numpy array.\n\n    Args:\n        path (pathlib.Path): Path to the RAW file.\n        shape (tuple[int, ...]): Shape of the RAW file.\n        dtype (np.dtype[np.number]):\n            Data type of the RAW file with the correct endianness.\n\n    Returns:\n        A numpy array made from the RAW data as `dtype` type and reshaped to `shape`.\n    \"\"\"\n    return np.fromfile(path, dtype=dtype).reshape(shape)\n</code></pre>"},{"location":"reference/API/drim2p/motion/","title":"motion","text":""},{"location":"reference/API/drim2p/motion/#drim2p.motion.motion","title":"<code>motion()</code>","text":"<p>Handles motion correction.</p> Source code in <code>src/drim2p/motion/__init__.py</code> <pre><code>@click.group()\ndef motion() -&gt; None:\n    \"\"\"Handles motion correction.\"\"\"\n</code></pre>"},{"location":"reference/API/drim2p/motion/correct/","title":"correct","text":""},{"location":"reference/API/drim2p/motion/correct/#drim2p.motion.correct.apply_motion_correction","title":"<code>apply_motion_correction(source, strategy=None, max_displacement=None, settings_path=None, recursive=False, include=None, exclude=None, compression=None, compression_opts=None, force=False)</code>","text":"<p>Applies motion correction on HDF5 chunks.</p> <p>The motion correction is configured through a TOML settings file (available from the source code in the resources directory). The file allows customising behaviour such as the strategy to use or the maximum displacement allowed.</p> <p>Parameters:</p> Name Type Description Default <code>source</code> <code>Path</code> <p>Source file or directory to convert. If a directory, the default is to look for HDF5 (.h5) files inside of it without recursion.</p> required <code>strategy</code> <code>Strategy | None</code> <p>Strategy to use for motion correction. This is ignored if a settings path is provided.</p> <code>None</code> <code>max_displacement</code> <code>tuple[int, int] | None</code> <p>Maximum expected pixel displacement for motion correction. This should be in the form x,y. This is ignored if a settings path is provided.</p> <code>None</code> <code>settings_path</code> <code>Path | None</code> <p>Path to the settings file to use. A strategy and max displacements can be provided together to remove the need for a settings file.</p> <code>None</code> <code>recursive</code> <code>bool</code> <p>Whether to search directories recursively when looking for HDF5 files.</p> <code>False</code> <code>include</code> <code>str | None</code> <p>Include filters to apply when searching for HDF5 files. This supports regular-expressions. Include filters are applied before any exclude filters.</p> <code>None</code> <code>exclude</code> <code>str | None</code> <p>Exclude filters to apply when searching for HDF5 files. This supports regular-expressions. Exclude filters are applied after all include filters.</p> <code>None</code> <code>compression</code> <code>COMPRESSION | None</code> <p>Compression algorithm to use.</p> <code>None</code> <code>compression_opts</code> <code>int | None</code> <p>Compression options to use with the given algorithm.</p> <code>None</code> <code>force</code> <code>bool</code> <p>Whether to ovewrite output datasets if they exist.</p> <code>False</code> Source code in <code>src/drim2p/motion/correct.py</code> <pre><code>def apply_motion_correction(\n    source: pathlib.Path,\n    strategy: models.Strategy | None = None,\n    max_displacement: tuple[int, int] | None = None,\n    settings_path: pathlib.Path | None = None,\n    recursive: bool = False,\n    include: str | None = None,\n    exclude: str | None = None,\n    compression: io.COMPRESSION | None = None,\n    compression_opts: int | None = None,\n    force: bool = False,\n) -&gt; None:\n    \"\"\"Applies motion correction on HDF5 chunks.\n\n    The motion correction is configured through a TOML settings file (available from\n    the source code in the resources directory). The file allows customising behaviour\n    such as the strategy to use or the maximum displacement allowed.\n\n    Args:\n        source (pathlib.Path):\n            Source file or directory to convert. If a directory, the default is to look\n            for HDF5 (.h5) files inside of it without recursion.\n        strategy (models.Strategy | None, optional):\n            Strategy to use for motion correction. This is ignored if a settings path is\n            provided.\n        max_displacement (tuple[int, int] | None, optional):\n            Maximum expected pixel displacement for motion correction. This should be in\n            the form x,y. This is ignored if a settings path is provided.\n        settings_path (pathlib.Path | None, optional):\n            Path to the settings file to use. A strategy and max displacements can be\n            provided together to remove the need for a settings file.\n        recursive (bool, optional):\n            Whether to search directories recursively when looking for HDF5 files.\n        include (str | None, optional):\n            Include filters to apply when searching for HDF5 files. This supports\n            regular-expressions. Include filters are applied before any exclude filters.\n        exclude (str | None, optional):\n            Exclude filters to apply when searching for HDF5 files. This supports\n            regular-expressions. Exclude filters are applied after all include filters.\n        compression (io.COMPRESSION | None, optional): Compression algorithm to use.\n        compression_opts (int | None, optional):\n            Compression options to use with the given algorithm.\n        force (bool, optional): Whether to ovewrite output datasets if they exist.\n    \"\"\"\n    # Parse settings\n    if settings_path is not None:\n        settings = models.MotionConfig.from_file(settings_path)\n    elif strategy is not None and max_displacement is not None:\n        settings = models.MotionConfig(strategy=strategy, displacement=max_displacement)\n    else:\n        _logger.error(\n            \"Please provide both a strategy and max displacement manually or through a \"\n            \"settings file.\"\n        )\n        return\n\n    for path in io.find_paths(source, [\".h5\"], include, exclude, recursive, True):\n        _logger.debug(f\"Motion correcting '{path}'.\")\n\n        _apply_motion_correction(path, settings, compression, compression_opts, force)\n</code></pre>"},{"location":"reference/API/drim2p/motion/correct/#drim2p.motion.correct.apply_motion_correction_command","title":"<code>apply_motion_correction_command(**kwargs)</code>","text":"<p>Applies motion correction on HDF5 chunks.</p> <p>The motion correction is configured through a TOML settings file (available from the source code in the resources directory). The file allows customising behaviour such as the strategy to use or the maximum displacement allowed.</p> Source code in <code>src/drim2p/motion/correct.py</code> <pre><code>@click.command(\"correct\")\n@click.argument(\n    \"source\",\n    required=False,\n    type=click.Path(\n        exists=True,\n        file_okay=True,\n        dir_okay=True,\n        readable=True,\n        path_type=pathlib.Path,\n    ),\n    callback=cli_utils.noop_if_missing,\n)\n@click.option(\n    \"-S\",\n    \"--strategy\",\n    required=False,\n    type=click.Choice(\n        [strategy.name for strategy in models.Strategy], case_sensitive=False\n    ),\n    help=(\n        \"Strategy to use for motion correction. This is ignored if a settings path is \"\n        \"provided.\"\n    ),\n)\n@click.option(\n    \"-d\",\n    \"--max-displacement\",\n    required=False,\n    type=str,\n    callback=_parse_max_displacement,\n    help=(\n        \"Maximum expected pixel displacement for motion correction. This should be in \"\n        \"the form x,y. This is ignored if a settings path is provided.\"\n    ),\n)\n@click.option(\n    \"-s\",\n    \"--settings-path\",\n    required=False,\n    type=click.Path(\n        exists=True, file_okay=True, dir_okay=False, path_type=pathlib.Path\n    ),\n    help=(\n        \"Path to the settings file to use. A strategy and max displacements can be \"\n        \"provided together to remove the need for a settings file.\"\n    ),\n)\n@click.option(\n    \"-r\",\n    \"--recursive\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to search directories recursively when looking for RAW files.\",\n)\n@click.option(\n    \"-i\",\n    \"--include\",\n    required=False,\n    default=None,\n    help=(\n        \"Include filters to apply when searching for RAW files. \"\n        \"This supports regular-expressions. Include filters are applied before any \"\n        \"exclude filters.\"\n    ),\n)\n@click.option(\n    \"-e\",\n    \"--exclude\",\n    required=False,\n    default=None,\n    help=(\n        \"Exclude filters to apply when searching for RAW files. \"\n        \"This supports regular-expressions. Exclude filters are applied after all \"\n        \"include filters.\"\n    ),\n)\n@click.option(\n    \"-c\",\n    \"--compression\",\n    required=False,\n    type=click.Choice(get_args(io.COMPRESSION), case_sensitive=False),\n    default=None,\n    callback=lambda _, __, x: x if x is None else x.lower(),\n    help=\"Compression algorithm to use.\",\n)\n@click.option(\n    \"--aggression\",\n    \"compression_opts\",\n    required=False,\n    type=click.IntRange(0, 9),\n    default=4,\n    help=(\n        \"Aggression level to use for GZIP compression. Lower means faster/worse \"\n        \"compression, higher means slower/better compression. Ignored if \"\n        \"'--compression' is not GZIP.\"\n    ),\n)\n@click.option(\n    \"--force\",\n    required=False,\n    is_flag=True,\n    help=\"Whether to overwrite output datasets if they exist.\",\n)\ndef apply_motion_correction_command(**kwargs: Any) -&gt; None:\n    \"\"\"Applies motion correction on HDF5 chunks.\n\n    The motion correction is configured through a TOML settings file (available from\n    the source code in the resources directory). The file allows customising behaviour\n    such as the strategy to use or the maximum displacement allowed.\n    \"\"\"\n    apply_motion_correction(**kwargs)\n</code></pre>"},{"location":"reference/API/drim2p/motion/correct/#drim2p.motion.correct.has_a_motion_corrected_dataset","title":"<code>has_a_motion_corrected_dataset(handle)</code>","text":"<p>Returns whether the given handle has an existing motion-corrected dataset.</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>File</code> <p>Handle to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>Whether such a dataset exists.</p> Source code in <code>src/drim2p/motion/correct.py</code> <pre><code>def has_a_motion_corrected_dataset(handle: h5py.File) -&gt; bool:\n    \"\"\"Returns whether the given handle has an existing motion-corrected dataset.\n\n    Args:\n        handle (h5py.File): Handle to check.\n\n    Returns:\n        Whether such a dataset exists.\n    \"\"\"\n    return handle.get(io.MOT_IMAGING_PATH) is not None\n</code></pre>"},{"location":"tutorials/","title":"Overview","text":"<p>This tutorial series will guide through step-by-step instructions on how to use <code>drim2p</code> as a command-line tool. Tutorials will show you how to prepare you data, motion correct it, draw ROIs, extract and decontaminate signals, and compute \u0394F/F\u2080.</p>"},{"location":"tutorials/#prerequisites","title":"Prerequisites","text":"<p>Before you start, you should have a 2-photon imaging file you wish to preprocess in the RAW binary format (i.e., uses the <code>.raw</code> extension). A small one, ideally under 250 MiB, will work best so you don't have to wait for it to be preprocessed between steps and you can easily run it on your own machine. Although small, you should expect to be able to discern individual cells when the image is maximum-projected for ROI drawing. Alongside this file, you should have an INI file with OME-XML metadata (failing that, you should have a standalone OME-XML metadata file).</p> <p>This INI file can contain any arbitrary metadata (but only a single section) about your RAW file which will be attached as attributes when converting to HDF5. No entry is mandatory but if you do not have a separate OME-XML file, your INI file will need to have an <code>ome.xml.string</code> entry that contains a valid OME-XML string with information about your file. This is required because the RAW file format does not contain any information about the data it stores and the OME-XML metadata is what is used to read and reshape the RAW file properly.</p> <p>An example directory with the required files looks like this:</p> <pre><code>tutorial/\n\u251c\u2500\u2500 imaging_file.ini\n\u251c\u2500\u2500 imaging_file.raw\n\u2514\u2500\u2500 imaging_file.xml\n</code></pre>"},{"location":"tutorials/#whats-next","title":"What's next?","text":"<p>When you have all the required files in a directory and you have a terminal open in that directory, you should move on to convertion to HDF5.</p>"},{"location":"tutorials/conversion-to-hdf5/","title":"Conversion to HDF5","text":"<p>The first step when working with RAW data is to convert it to a file format that allows shaping it correctly and appending metadata about its datatype, acquisition, etc. <code>drim2p</code> uses the HDF5 file format.</p>"},{"location":"tutorials/conversion-to-hdf5/#converting","title":"Converting","text":"<p>With a terminal open in the directory with your files, simply run:</p> <pre><code>drim2p convert raw .\n</code></pre> <p>Note</p> <p>For many of the commands in these tutorials, you will see a <code>.</code> after the name of the command or subcommand. This is used to denote the current working directory and is used by <code>drim2p</code> to find the file it should process. If you are working from outside the directory where your files are located, simply replace the <code>.</code> with the absolute or relative path to the relevant folder.</p> <p>If all goes well, you will see some output along these lines:</p> <pre><code>Converting 'imaging_file.raw'.\nFinished converting 'imaging_file.raw'.\n</code></pre> <p>And your directory will now contain an extra <code>.h5</code> file:</p> <pre><code>tutorial/\n\u251c\u2500\u2500 imaging_file.h5  (NEW)\n\u251c\u2500\u2500 imaging_file.ini\n\u251c\u2500\u2500 imaging_file.raw\n\u2514\u2500\u2500 imaging_file.xml\n</code></pre> <p>If you see a warning but no error, you file should still be converted properly, but some metadata might not be conserved.  </p> <p>If you see an error, then something prevented the conversion from going ahead. The most common error looks like this:</p> <pre><code>Failed to retrieve OME-XML metadata from INI file or directly through XML file. \n</code></pre> <p>If you get this error, you should ensure you have the proper file structure as described in the overview then try again.</p> <p>If you get a different error, you should read the message to try and understand what went wrong. If you are not sure how to solve it, try looking for the error message on the issues page.</p> <p>Note</p> <p>Since this is the first step, and to get you on the right track, this tutorial tries to cover cases where the command does not run properly. Future tutorials will only present what the expected output is. If you run into issues in those tutorials, follow the instructions detailed above and have a look at the issues.</p>"},{"location":"tutorials/conversion-to-hdf5/#whats-next","title":"What's next?","text":"<p>You are now ready to preprocess your data. To begin, move on to motion correction.</p>"},{"location":"tutorials/dff-calculation/","title":"\u0394F/F\u2080 computation","text":"<p>\u0394F/F\u2080 is a normalisation technique that enables comparing signal values between recordings as well as between cells in the same recording.</p> <p>There are multiple ways to compute F\u2080, using a percentile, the mean, the median, etc. By default, <code>drim2p</code> computes F\u2080 to be the 5th percentile of the fluorescence for the whole signal.</p> <p>It is also possible to use a rolling window to continually update the F\u2080 value throughout the signal.</p> <p>This tutorial focuses on using the default (5th percentile with no rolling window). For a more in-depth guide to customising the computation, see the how-to guide and the CLI reference.</p>"},{"location":"tutorials/dff-calculation/#calculating-ff0","title":"Calculating \u0394F/F\u2080","text":"<p>To compute \u0394F/F\u2080, simply run:</p> <pre><code>drim2p deltaf .\n</code></pre> <p>If all goes well, you will see output along these lines (the computation should be very fast for any size of recording):</p> <pre><code>Computing \u0394F/F\u2080 for 'imaging_file.h5'.\nSaved \u0394F/F\u2080.\n</code></pre>"},{"location":"tutorials/dff-calculation/#whats-next","title":"What's next?","text":"<p>This is the final tutorial guiding you through the <code>drim2p</code> pipeline. Now that you have \u0394F/F\u2080 traces, you can carry out custom analysis and plotting, or optionally, you can use the provided template for spike inference as described in the how-to guide.</p>"},{"location":"tutorials/motion-correction/","title":"Motion correction","text":"<p>During 2-photon calcium imaging, motion artifacts can pollute your raw recording and needs to corrected in order to enable analyses using ROIs (Regions Of Interest).</p> <p><code>drim2p</code> uses the <code>SIMA</code> (DOI) library to carry out motion correction.</p>"},{"location":"tutorials/motion-correction/#motion-settings","title":"Motion settings","text":"<p>Motion correction requires some additional information related to the strategy to use as well as the maximum expected displacement of pixels throughout the recording. This information is passed along to <code>drim2p</code> using a settings file. For this tutorial, we will use the default file available from the repository. Once you understand the workflow a bit better, you can customise it as described in the how-to guide.</p> <p>In order to inform <code>drim2p</code> of which settings to use, you should download the default settings file and move it to the directory where your recording is.</p> <p>You should then have the following file structure:</p> <pre><code>tutorial/\n\u251c\u2500\u2500 imaging_file.h5\n\u251c\u2500\u2500 imaging_file.ini\n\u251c\u2500\u2500 imaging_file.raw\n\u251c\u2500\u2500 imaging_file.xml\n\u2514\u2500\u2500 settings.toml.base  (NEW)\n</code></pre>"},{"location":"tutorials/motion-correction/#motion-correcting","title":"Motion correcting","text":"<p>From there, motion correction is as easy as conversion. All you need to do if run the following command:</p> <pre><code>drim2p motion correct . --settings-path settings.toml.base\n</code></pre> <p>If all goes well, you will see some output along these lines:</p> <pre><code>Applying motion correction for 'imaging_file' using DiscreteFourier2D.\nFinished motion correction in 0h 1m 0.00s.\nSaved motion correction to file.\n</code></pre> <p>The motion corrected data will be saved automatically. However, you won't see a new file in your directory. That is one of the strengths of HDF5. You can store multiple bits of information inside the same file. Think of it as a ZIP archive, it's essentially a folder structure but all inside of one file.</p> <p>Note</p> <p>You don't need to keep the <code>settings.toml</code> file around your data. When you apply motion correction to a dataset, the settings used are added to the metadata of the motion corrected dataset.</p>"},{"location":"tutorials/motion-correction/#whats-next","title":"What's next?","text":"<p>After motion correction, you will now be able to select ROIs on your recording in order to then analyse their signals. <code>drim2p</code> provides a GUI (Graphical User Interface) to draw ROIs on.</p>"},{"location":"tutorials/roi-drawing/","title":"ROI drawing","text":"<p>ROI drawing is the only step for which your manual input is required. Once your data has been motion corrected, you need to start the ROI drawing interface and manually draw around the cells present in your recording. Using these ROIs, the rest of the workflow will then be able to extract, decontaminate, and analyse the cell signals present.</p>"},{"location":"tutorials/roi-drawing/#starting-the-gui","title":"Starting the GUI","text":"<p>The command to use to start the GUI is:</p> <pre><code>drim2p draw roi .\n</code></pre> <p>This step can take a very different amount of time depending on the size, and storage modality, of your recording. If you only used a small recording as recommended, this should open the GUI in less than 30 seconds. However, for larger files (and for files on remote filesystems), this can start to take a minute or two (longer on network drives).</p> <p>What is happening under the hood when you run the command is that <code>drim2p</code> is loading the file and making both a mean intensity projection of the whole recording as well as grouped mean intensity projections every 10 frames.</p> <p>If all goes well, you will see this log message:</p> <pre><code>Opening 'imaging_file.h5'.\n</code></pre> <p>Followed by the GUI opening up. It will look like this with your own data opened on the right:</p> <p></p> Image 1: ROI drawing GUI. <p>Note</p> <p>For larger and remote files, you might want to use the <code>--lazy</code> option (i.e., <code>drim2p draw roi . --lazy</code>) to avoid computing the mean intensity projection over the whole file. This will considerably speed up the GUI startup time, but will result in no mean intensity projection being shown and scrolling through grouped Z projections feeling more sluggish.</p>"},{"location":"tutorials/roi-drawing/#understanding-the-gui","title":"Understanding the GUI","text":"Image 2: Annotated drawing ROI GUI<p>For a complete tutorial of the <code>napari</code> viewer (the GUI), you can follow this official tutorial. The tutorial provided here will only touch on the relevant parts for ROI drawing.</p>"},{"location":"tutorials/roi-drawing/#1-controls","title":"1. Controls","text":"<p>The section labelled 1 is where you can pick the different interactions your mouse can do. By default, you will have the pan tool selected. This means you can drag the view (labelled 3) while the left mouse button is pressed down.</p> <p>For ROI drawing, you will be using the button on the second row, fifth column (the irregular hexagon). Using this, you can draw ROIs by dragging your mouse around the region you want to mark.</p>"},{"location":"tutorials/roi-drawing/#2-layer-list","title":"2. Layer list","text":"<p><code>napari</code> works using layers. The layer list contains three layers: 'ROIs', 'Grouped Z projections', and 'Mean intensity projection' (missing if using <code>--lazy</code>).</p> <p>By default, you will see that only the 'ROIs' and 'Mean intensity projection' are visible (the eye icon to the left of their name is toggled on) while the 'Grouped Z projections' is not. This allows you to use the overall projection to draw your ROIs before showing the 'Grouped Z projections' and verifying that motion correction was done properly. You can toggle the visibility of each layer by clicking the eye icon.</p> <p>When playing around with layers, it is possible that you will select a layer other than 'ROIs' (e.g., by left clicking on the name of another layer). Doing so will change what is available from the controls and will prevent you from drawing ROIs. To go back to ROI drawing, simply click on the 'ROIs' layer by left clicking on its name.</p>"},{"location":"tutorials/roi-drawing/#3-view","title":"3. View","text":"<p>The view is where all the layers are displayed, stacked on top of each other. Using the default pan tool, you can drag it around and, using the mouse wheel, you can zoom in and out.</p>"},{"location":"tutorials/roi-drawing/#drawing-rois","title":"Drawing ROIs","text":"<p>To draw ROIs, select the tool shown in the GIF below. You can then press and hold left click to draw around the region of interest.</p> <p></p> Image 3: Drawing ROIs."},{"location":"tutorials/roi-drawing/#adjusting-rois","title":"Adjusting ROIs","text":""},{"location":"tutorials/roi-drawing/#moving-vertices","title":"Moving vertices","text":"<p>Once you have drawn an ROI, you can adjust the vertices it is made of by moving them around until you are happy with it.</p> <p></p> Image 4: Moving vertices."},{"location":"tutorials/roi-drawing/#adding-vertices","title":"Adding vertices","text":"<p>If the vertices generated for your ROI do not fit the shape you want, you can add vertices to it.</p> <p></p> Image 5: Adding vertices."},{"location":"tutorials/roi-drawing/#deleting-vertices","title":"Deleting vertices","text":"<p>If there are vertices that aren't necessary to capture the ROI, you can remove vertices from it.</p> <p></p> Image 6: Deleting vertices."},{"location":"tutorials/roi-drawing/#deleting-rois","title":"Deleting ROIs","text":"<p>If you have added an ROI somewhere you didn't mean to or don't want to consider a certain cell after more thought, you can remove ROIs.</p> <p></p> Image 7: Deleting ROIs."},{"location":"tutorials/roi-drawing/#scrolling-grouped-projections","title":"Scrolling grouped projections","text":"<p>Once you have drawn the ROIs and you are satisfied with them, you can toggle the visibility of the 'Grouped Z projections' and play around with the slider and arrows at the bottom to navigate through the projections (by default every 10 frames). This allows you to confirm your ROIs capture the activity of the cells in the recording and allows validating the motion correction worked properly.</p> <p></p> Image 8: Navigating grouped projections."},{"location":"tutorials/roi-drawing/#finalising-the-rois","title":"Finalising the ROIs","text":"<p>When you are happy with your ROIs and you are ready to move to the next step, simply close the GUI window and the ROIs will be saved.</p> <p>If, for one reason or another, you have drawn a bunch of ROIs but do not want them to be saved, you should delete the 'ROIs' layer by selecting it (left click on its name) and clicking the bin icon above it and to the right. This will delete all the ROIs drawn during the current session since starting the GUI. Upon closing the GUI, any modification to the ROIs will be reverted.</p>"},{"location":"tutorials/roi-drawing/#editing-existing-rois","title":"Editing existing ROIs","text":"<p>Once ROIs have been saved to the HDF5 file, you can come back to it later on, run <code>drim2p draw roi .</code> and the GUI will reopen the file, with all its ROIs already drawn. Note that at this point, deleting the ROIs layer will not result in those pre-existing ROIs being deleted. If you wish to delete those, you will need to delete the ROIs without deleting the layer (this can be done by selecting all the ROIs with the select tool and pressing <code>delete</code> or <code>backspace</code> on your keyboard).</p>"},{"location":"tutorials/roi-drawing/#whats-next","title":"What's next?","text":"<p>Now that you have ROIs that should have their signals preprocessed, you should move on to signal extraction and decontamination.</p>"},{"location":"tutorials/signal-extraction-and-decontamination/","title":"Signal extraction and decontamination","text":"<p><code>drim2p</code> uses FISSA (DOI) for signal extraction and decontamination. Both of those steps are done in one command.</p>"},{"location":"tutorials/signal-extraction-and-decontamination/#running-the-command","title":"Running the command","text":"<p>Like previous steps in this tutorial, extraction and decontamination only requires a single command:</p> <pre><code>drim2p extract signal .\n</code></pre> <p>If all goes well, you will see something along these lines:</p> <pre><code>Extracting and decontaminating signal for 'imaging_file'.\nExtracting traces: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00, 3548.48it/s]\nFinished extracting raw signals from 1 ROIs across 1 trials in 1 min, 0 sec.\nSeparating data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1/1 [00:00&lt;00:00, 41.16it/s]\nFinished separating signals from 1 ROIs across 1 trials in 1 min, 0 sec\nFinished extracting signal.\n</code></pre> <p>Once again, no extra file should be added to the directory, instead the extracted signals will be embedded into the HDF5 file.</p> <p>Note</p> <p>FISSA outputs signal arrays in the shape (5, timepoints), where the first index is the \"true\" signal and the next four are the neuropil ones. <code>drim2p</code> only saves the \"true\" signal under the normal preprocessing group. However, the neuropil signals are still saved in the QA group.</p>"},{"location":"tutorials/signal-extraction-and-decontamination/#whats-next","title":"What's next?","text":"<p>The next step in the workflow is to compute \u0394F/F\u2080 for the extracted signals.</p>"}]}